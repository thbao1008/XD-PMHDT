# üéØ NVIDIA GPU Priority - ∆Øu Ti√™n GPU NVIDIA (R·ªùi)

## T·ªïng quan

H·ªá th·ªëng t·ª± ƒë·ªông **∆∞u ti√™n s·ª≠ d·ª•ng NVIDIA GPU (r·ªùi)** v√† **b·ªè qua GPU t√≠ch h·ª£p AMD** khi training.

## T·ª± ƒë·ªông Detection

### 1. NVIDIA GPU Detection

Code t·ª± ƒë·ªông t√¨m GPU c√≥ t√™n ch·ª©a:
- `nvidia`
- `geforce`
- `rtx`
- `gtx`
- `quadro`
- `tesla`

### 2. ∆Øu ti√™n GPU r·ªùi

- ‚úÖ **S·ª≠ d·ª•ng**: NVIDIA GPU (r·ªùi) - RTX, GTX, Quadro, Tesla
- ‚ùå **B·ªè qua**: AMD GPU t√≠ch h·ª£p - Radeon Graphics, Vega, etc.

## Ki·ªÉm tra GPU

```bash
npm run aiesp:gpu:check
```

**Output v√≠ d·ª•:**
```json
{
  "cuda_available": true,
  "nvidia_gpu_available": true,
  "nvidia_gpu_index": 0,
  "nvidia_gpu_name": "NVIDIA GeForce RTX 3060",
  "device": "cuda:0",
  "torch_available": true,
  "total_gpus": 2,
  "all_gpus": [
    "NVIDIA GeForce RTX 3060",      ‚Üê S·∫Ω s·ª≠ d·ª•ng GPU n√†y
    "AMD Radeon Graphics"           ‚Üê S·∫Ω b·ªè qua GPU n√†y
  ]
}
```

## C√°ch ho·∫°t ƒë·ªông

### 1. Detection Phase

```python
# T·ª± ƒë·ªông detect NVIDIA GPU
for i in range(torch.cuda.device_count()):
    device_name = torch.cuda.get_device_name(i)
    if 'nvidia' in device_name.lower() or 'geforce' in device_name.lower():
        NVIDIA_GPU_INDEX = i
        break
```

### 2. Training Phase

```python
# Ch·ªâ s·ª≠ d·ª•ng NVIDIA GPU
device = torch.device(f'cuda:{NVIDIA_GPU_INDEX}')
torch.cuda.set_device(NVIDIA_GPU_INDEX)
```

### 3. Environment Variables

```javascript
// Ch·ªâ hi·ªÉn th·ªã NVIDIA GPU cho PyTorch
CUDA_VISIBLE_DEVICES: nvidiaGpuIndex  // V√≠ d·ª•: "0"
```

## L·ª£i √≠ch

- ‚úÖ **Performance t·ªët h∆°n**: NVIDIA GPU th∆∞·ªùng m·∫°nh h∆°n GPU t√≠ch h·ª£p
- ‚úÖ **T·ª± ƒë·ªông**: Kh√¥ng c·∫ßn c·∫•u h√¨nh th·ªß c√¥ng
- ‚úÖ **Tr√°nh conflict**: Kh√¥ng s·ª≠ d·ª•ng GPU t√≠ch h·ª£p (th∆∞·ªùng y·∫øu h∆°n)
- ‚úÖ **Full utilization**: T·∫≠n d·ª•ng to√†n b·ªô NVIDIA GPU

## Troubleshooting

### NVIDIA GPU kh√¥ng ƒë∆∞·ª£c detect

**Ki·ªÉm tra:**
```bash
python -c "import torch; print(torch.cuda.get_device_name(0))"
```

**N·∫øu GPU kh√¥ng ph·∫£i NVIDIA:**
- Code s·∫Ω fallback v·ªÅ GPU ƒë·∫ßu ti√™n
- Ho·∫∑c s·ª≠ d·ª•ng CPU n·∫øu kh√¥ng c√≥ CUDA

### Mu·ªën force s·ª≠ d·ª•ng GPU c·ª• th·ªÉ

Set environment variable:
```bash
# Windows PowerShell
$env:CUDA_VISIBLE_DEVICES="0"  # Index c·ªßa NVIDIA GPU

# Linux/Mac
export CUDA_VISIBLE_DEVICES=0
```

### C√≥ nhi·ªÅu NVIDIA GPU

H·ªá th·ªëng s·∫Ω ch·ªçn GPU ƒë·∫ßu ti√™n ƒë∆∞·ª£c detect. N·∫øu mu·ªën ch·ªçn GPU kh√°c:

1. Check t·∫•t c·∫£ GPUs:
   ```bash
   npm run aiesp:gpu:check
   ```

2. Set CUDA_VISIBLE_DEVICES v·ªõi index mong mu·ªën:
   ```bash
   $env:CUDA_VISIBLE_DEVICES="1"  # S·ª≠ d·ª•ng GPU th·ª© 2
   ```

## V√≠ d·ª•

### Setup th√¥ng th∆∞·ªùng

```
M√°y t√≠nh c√≥:
- NVIDIA GeForce RTX 3060 (GPU r·ªùi) ‚Üê S·∫Ω s·ª≠ d·ª•ng
- AMD Radeon Graphics (GPU t√≠ch h·ª£p) ‚Üê S·∫Ω b·ªè qua

‚Üí H·ªá th·ªëng t·ª± ƒë·ªông ch·ªçn RTX 3060
```

### Training

```bash
npm run aiesp:gpu:train
```

**Output:**
```
[Local GPU] ‚úÖ NVIDIA GPU (r·ªùi) selected: NVIDIA GeForce RTX 3060
[Local GPU] GPU Index: 0
[Local GPU] üöÄ Using NVIDIA GPU (r·ªùi) to process 500 patterns...
[Local GPU] ‚úÖ NVIDIA GPU processing completed with full performance
```

## Next Steps

Sau khi setup, ch·∫°y:
```bash
npm run aiesp:learn
```

H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông:
- ‚úÖ Detect NVIDIA GPU m·ªói 10 ph√∫t
- ‚úÖ Train v·ªõi NVIDIA GPU n·∫øu c√≥
- ‚úÖ B·ªè qua AMD GPU t√≠ch h·ª£p

