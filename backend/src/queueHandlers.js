// backend/src/queueHandlers.js
import { registerProcessor } from "./utils/queue.js";
import * as learnerService from "./services/learnerService.js";
import * as learnerAiService from "./services/learnerAiService.js";
import { runWhisperX } from "./utils/whisperxRunner.js";
import path from "path";
import fs from "fs";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ƒê·ªçc sampleTranscripts t·ª´ JSON b·∫±ng fs (kh√¥ng d√πng assert) - optional
let sampleTranscripts = [];
let sampleTexts = [];
try {
  const sampleTranscriptsPath = path.resolve(__dirname, "../ai_models/sampleTranscripts.json");
  if (fs.existsSync(sampleTranscriptsPath)) {
    sampleTranscripts = JSON.parse(fs.readFileSync(sampleTranscriptsPath, "utf-8"));
    sampleTexts = Array.isArray(sampleTranscripts) ? sampleTranscripts.map(s => s.text) : [];
  } else {
    console.warn("‚ö†Ô∏è sampleTranscripts.json not found, using empty array");
  }
} catch (err) {
  console.warn("‚ö†Ô∏è Failed to load sampleTranscripts.json:", err.message);
  sampleTranscripts = [];
  sampleTexts = [];
}

function audioUrlToLocalPath(audioUrl) {
  const m = String(audioUrl || "").match(/\/uploads\/(.+)$/);
  if (!m) return null;
  const filename = m[1];
  return path.resolve(process.cwd(), "uploads", filename);
}

registerProcessor("analyzeSubmission", async (job) => {
  const { submissionId } = job.data;
  console.log("üîÑ Processing analyzeSubmission job: - queueHandlers.js:27", submissionId);

  const sub = await learnerService.getSubmissionById(submissionId);
  if (!sub) {
    console.warn("‚ö†Ô∏è Submission not found: - queueHandlers.js:31", submissionId);
    return;
  }

  console.log("üìÑ Submission loaded: - queueHandlers.js:35", {
    id: sub.id,
    audio_url: sub.audio_url,
    transcriptExists: !!sub.transcript,
  });

  let transcript = sub.transcript ?? null;

  // N·∫øu ch∆∞a c√≥ transcript th√¨ ch·∫°y WhisperX
  if (!transcript) {
    if (!sub.audio_url) {
      console.warn("‚ö†Ô∏è No audio_url to transcribe: - queueHandlers.js:46", submissionId);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }

    const localPath = audioUrlToLocalPath(sub.audio_url);
    if (!localPath || !fs.existsSync(localPath)) {
      console.error("‚ùå Local audio file not found: - queueHandlers.js:53", localPath);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }

    try {
      console.log("üîä Transcribing audio: - queueHandlers.js:59", localPath);
      const { json: transcriptJson } = await runWhisperX(localPath, {
        model: "base",
        computeType: "float32",
        timeoutMs: 3 * 60 * 1000,
      });

      if (transcriptJson) {
        // L∆∞u transcript
        await learnerService.updateSubmissionTranscript(submissionId, transcriptJson);
        transcript = transcriptJson;

        // L∆∞u segments n·∫øu c√≥
        if (Array.isArray(transcriptJson.segments)) {
          await learnerService.updateSubmissionSegments(submissionId, transcriptJson.segments);
        }

        console.log("üìù Transcript + segments saved: - queueHandlers.js:76", submissionId);
      } else {
        console.warn("‚ö†Ô∏è Empty transcript JSON: - queueHandlers.js:78", submissionId);
        await learnerService.updateSubmissionStatus(submissionId, "pending_transcription");
        return;
      }
    } catch (err) {
      console.error("‚ùå Transcription failed: - queueHandlers.js:83", submissionId, err);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }
  }

  // Ph√¢n t√≠ch transcript b·∫±ng learnerAiService
  try {
    console.log("üß† Analyzing transcript: - queueHandlers.js:91", submissionId);

    const challenge = await learnerService.getChallengeById(sub.challenge_id);

    const analysis = await learnerAiService.analyzeLearnerTranscript(transcript, {
      runTopicDetection: true,
      challenge,
      sampleTranscripts: sampleTexts
    });

    if (!analysis || typeof analysis !== "object") {
      console.error("‚ùå Invalid analysis result: - queueHandlers.js:102", submissionId, analysis);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }

    await learnerService.updateSubmissionAnalysis(submissionId, { ...analysis, transcript });
    await learnerService.updateSubmissionStatus(submissionId, "completed");
    console.log("‚úÖ AI analysis saved: - queueHandlers.js:109", submissionId);
  } catch (err) {
    console.error("‚ùå AI analysis failed: - queueHandlers.js:111", submissionId, err);
    await learnerService.updateSubmissionStatus(submissionId, "failed");
  }
});

// Queue handler ƒë·ªÉ x·ª≠ l√Ω audio feedback t·ª´ mentor: transcribe v√† g·ª≠i cho AI h·ªçc
registerProcessor("processMentorAudioFeedback", async (job) => {
  const { feedbackId, audioUrl, submissionId, scores } = job.data;
  console.log("üîÑ Processing mentor audio feedback: - queueHandlers.js:118", { feedbackId, audioUrl });

  if (!audioUrl) {
    console.warn("‚ö†Ô∏è No audio_url for feedback: - queueHandlers.js:121", feedbackId);
    return;
  }

  const localPath = audioUrlToLocalPath(audioUrl);
  if (!localPath || !fs.existsSync(localPath)) {
    console.error("‚ùå Local audio file not found: - queueHandlers.js:126", localPath);
    return;
  }

  try {
    // Transcribe audio feedback
    console.log("üîä Transcribing mentor feedback audio: - queueHandlers.js:135", localPath);
    const { json: transcriptJson } = await runWhisperX(localPath, {
      model: "base",
      computeType: "float32",
      timeoutMs: 3 * 60 * 1000,
    });

    // Extract text from transcript JSON
    let transcriptText = "";
    if (transcriptJson) {
      if (typeof transcriptJson.text === "string") {
        transcriptText = transcriptJson.text;
      } else if (Array.isArray(transcriptJson.words)) {
        transcriptText = transcriptJson.words.map(w => w.text || w.word || "").join(" ");
      } else if (Array.isArray(transcriptJson.segments)) {
        transcriptText = transcriptJson.segments.map(s => s.text || "").join(" ");
      }
    }

    if (!transcriptText) {
      console.warn("‚ö†Ô∏è Empty transcript for feedback: - queueHandlers.js:150", feedbackId);
      return;
    }

    // L·∫•y context c·ªßa submission ƒë·ªÉ AI h·ªçc
    let submissionContext = {};
    if (submissionId) {
      try {
        const sub = await learnerService.getSubmissionById(submissionId);
        if (sub) {
          const learnerTranscript = typeof sub.transcript === "string" 
            ? sub.transcript 
            : (sub.transcript?.text || "");
          submissionContext = {
            learner_transcript: learnerTranscript,
            challenge_title: sub.challenge?.title || "",
            challenge_description: sub.challenge?.description || ""
          };
        }
      } catch (err) {
        console.warn("‚ö†Ô∏è Could not load submission context: - queueHandlers.js:156", err);
      }
    }

    // G·ª≠i cho AI ƒë·ªÉ h·ªçc t·ª´ c√°ch ƒë√°nh gi√° c·ªßa mentor
    const mentorAiService = await import("./services/mentorAiService.js");
    const learningResult = await mentorAiService.learnFromMentorFeedback(
      transcriptText,
      scores || {},
      submissionContext
    );

    if (learningResult) {
      console.log("‚úÖ AI learned from mentor feedback: - queueHandlers.js:165", {
        feedbackId,
        criteria: learningResult.evaluation_criteria?.length || 0,
        suggestions: learningResult.improvement_suggestions?.length || 0
      });
      
      // C√≥ th·ªÉ l∆∞u learningResult v√†o database ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y
      // V√≠ d·ª•: t·∫°o b·∫£ng mentor_feedback_learnings ho·∫∑c c·∫≠p nh·∫≠t feedbacks table
      // TODO: L∆∞u learningResult v√†o database n·∫øu c·∫ßn
    }

    // C·∫≠p nh·∫≠t feedback v·ªõi transcript (n·∫øu c·∫ßn l∆∞u transcript v√†o DB)
    // C√≥ th·ªÉ th√™m c·ªôt transcript_text v√†o b·∫£ng feedbacks
    console.log("üìù Mentor feedback transcribed: - queueHandlers.js:177", feedbackId);
  } catch (err) {
    console.error("‚ùå Process mentor audio feedback failed: - queueHandlers.js:180", feedbackId, err);
  }
});

// Queue handler ƒë·ªÉ x·ª≠ l√Ω speaking round (transcription + AI analysis)
registerProcessor("processSpeakingRound", async (job) => {
  const { roundId, audioUrl, prompt, level } = job.data;
  console.log("üîÑ Processing speaking round: - queueHandlers.js", roundId);

  const pool = (await import("./config/db.js")).default;
  const { runWhisperX } = await import("./utils/whisperxRunner.js");
  const path = (await import("path")).default;
  const fs = (await import("fs")).default;
  const aiService = await import("./services/aiService.js");

  try {
    // Transcribe audio
    const localPath = audioUrl.startsWith("/uploads/")
      ? path.join(process.cwd(), audioUrl)
      : audioUrl;

    let transcript = null;
    if (fs.existsSync(localPath)) {
      try {
        const { json: transcriptJson } = await runWhisperX(localPath, {
          model: "base",
          computeType: "float32"
        });
        transcript = transcriptJson;
      } catch (err) {
        console.error("‚ùå Transcription error:", err);
        return;
      }
    }

    // Analyze v·ªõi AI
    let analysis = null;
    let score = 0;
    let feedback = "";
    let errors = [];
    let correctedText = "";
    let speechRate = 0;
    let missingWords = [];

    if (transcript) {
      const transcriptText =
        transcript.text ||
        (transcript.segments || [])
          .map((s) => s.text || "")
          .join(" ");

      // QUAN TR·ªåNG: Ki·ªÉm tra n·∫øu kh√¥ng n√≥i g√¨ (transcript r·ªóng ho·∫∑c kh√¥ng c√≥ t·ª´ n√†o) th√¨ score = 0
      if (!transcriptText || !transcriptText.trim()) {
        score = 0;
        feedback = "B·∫°n ch∆∞a n√≥i g√¨. H√£y th·ª≠ l·∫°i v√† n√≥i to, r√µ r√†ng.";
        missingWords = prompt.toLowerCase().split(/\s+/).filter(w => w.length > 0);
        // ƒê·∫£m b·∫£o missing_words ƒë∆∞·ª£c l∆∞u v√†o analysis ngay c·∫£ khi kh√¥ng n√≥i g√¨
        analysis = {
          feedback,
          grammar_errors: [],
          speaking_score: 0,
          vocabulary_score: 0,
          speech_rate: 0,
          missing_words: missingWords
        };
      } else {
        try {
          // Ph√¢n t√≠ch ph√°t √¢m v√† so s√°nh v·ªõi prompt
          const expectedWords = prompt.toLowerCase().split(/\s+/).filter(w => w.length > 0);
          const spokenWords = transcriptText.toLowerCase().split(/\s+/).filter(w => w.length > 0);
          
          // T√≠nh missing_words: t·ª´ n√†o trong expected kh√¥ng c√≥ trong spoken
          missingWords = expectedWords.filter(ew => {
            const cleanExpected = ew.replace(/[.,!?;:]/g, "");
            return !spokenWords.some(sw => {
              const cleanSpoken = sw.replace(/[.,!?;:]/g, "");
              return cleanSpoken === cleanExpected || 
                     cleanSpoken.includes(cleanExpected) || 
                     cleanExpected.includes(cleanSpoken);
            });
          });
          
          // QUAN TR·ªåNG: N·∫øu kh√¥ng match t·ª´ n√†o, score = 0
          const matchedWords = expectedWords.filter(ew => {
            const cleanExpected = ew.replace(/[.,!?;:]/g, "");
            return spokenWords.some(sw => {
              const cleanSpoken = sw.replace(/[.,!?;:]/g, "");
              return cleanSpoken === cleanExpected || 
                     cleanSpoken.includes(cleanExpected) || 
                     cleanExpected.includes(cleanSpoken);
            });
          });
          
          if (matchedWords.length === 0) {
            // Kh√¥ng n√≥i ƒë√∫ng t·ª´ n√†o = 0 ƒëi·ªÉm
            score = 0;
            feedback = "B·∫°n ch∆∞a n√≥i ƒë√∫ng t·ª´ n√†o. H√£y nghe l·∫°i v√† n√≥i theo prompt.";
          } else {
            // T√≠nh ƒëi·ªÉm d·ª±a tr√™n ph·∫ßn trƒÉm t·ª´ ƒë·ªçc ƒë√∫ng (0-100 ƒëi·ªÉm)
            const totalWords = expectedWords.length;
            const correctWords = matchedWords.length;
            const percentage = totalWords > 0 ? (correctWords / totalWords) * 100 : 0;
            // T√≠nh ƒëi·ªÉm: ph·∫ßn trƒÉm t·ª´ 0-100, l√†m tr√≤n 1 ch·ªØ s·ªë th·∫≠p ph√¢n
            score = Math.round(percentage * 10) / 10;
            score = Math.min(100, Math.max(0, score)); // ƒê·∫£m b·∫£o ƒëi·ªÉm trong kho·∫£ng 0-100
            
            // T√≠nh t·ªëc ƒë·ªô n√≥i (t·ª´/ph√∫t)
            const timeTaken = job.data.time_taken || 30; // seconds
            speechRate = Math.round((spokenWords.length / timeTaken) * 60);
            
            // T·∫°o feedback d·ª±a tr√™n ƒëi·ªÉm s·ªë (thang 100)
            let feedbackText = "";
            if (score >= 90) {
              feedbackText = "Xu·∫•t s·∫Øc! B·∫°n ƒë√£ ƒë·ªçc g·∫ßn nh∆∞ ho√†n h·∫£o. H√£y ti·∫øp t·ª•c ph√°t huy!";
            } else if (score >= 70) {
              feedbackText = "T·ªët! B·∫°n ƒë√£ ƒë·ªçc ƒë√∫ng ph·∫ßn l·ªõn c√°c t·ª´. H√£y c·ªë g·∫Øng ƒë·ªçc ƒë·∫ßy ƒë·ªß h∆°n.";
            } else if (score >= 50) {
              feedbackText = "Kh√° t·ªët! B·∫°n ƒë√£ ƒë·ªçc ƒë√∫ng h∆°n m·ªôt n·ª≠a. H√£y luy·ªán t·∫≠p th√™m ƒë·ªÉ c·∫£i thi·ªán.";
            } else if (score >= 30) {
              feedbackText = "C·∫ßn c·∫£i thi·ªán. B·∫°n ƒë√£ ƒë·ªçc ƒë√∫ng m·ªôt s·ªë t·ª´. H√£y l·∫Øng nghe k·ªπ v√† luy·ªán t·∫≠p nhi·ªÅu h∆°n.";
            } else {
              feedbackText = "C·∫ßn luy·ªán t·∫≠p nhi·ªÅu h∆°n. H√£y nghe k·ªπ ph√°t √¢m v√† th·ª≠ l·∫°i.";
            }
            
            if (missingWords.length > 0) {
              feedbackText += ` C√°c t·ª´ c·∫ßn luy·ªán t·∫≠p: ${missingWords.slice(0, 5).join(", ")}${missingWords.length > 5 ? "..." : ""}.`;
            }
            
            const analysisPrompt = `You are an English pronunciation and speaking tutor. Provide detailed feedback for the learner.

Expected text: "${prompt}"
Learner's transcript: "${transcriptText}"
Time taken: ${timeTaken} seconds
Speech rate: ${speechRate} words/minute
Missing words: ${missingWords.length > 0 ? missingWords.join(", ") : "None"}
Score: ${score}/100 (based on ${correctWords}/${totalWords} words correct)

Please provide a comprehensive analysis in JSON format:
{
  "vocabulary_score": <number 0-100, based on vocabulary usage and word accuracy>,
  "speech_rate": ${speechRate},
  "missing_words": ${JSON.stringify(missingWords)},
  "grammar_errors": ["<grammar error 1>", "<grammar error 2>", ...],
  "feedback": "<detailed feedback in Vietnamese about pronunciation, grammar, and overall performance. Include encouragement and specific suggestions>"
}

IMPORTANT: Respond ONLY with valid JSON, no markdown code blocks, no explanations.`;

            const response = await aiService.callOpenRouter(
              [{ role: "user", content: analysisPrompt }],
              { model: "openai/gpt-4o-mini", temperature: 0.7 }
            );

            let content = response.choices?.[0]?.message?.content || "{}";
            
            // Parse JSON (handle markdown code blocks if any)
            content = content.trim();
            const codeBlockRegex = /```(?:json)?\s*([\s\S]*?)```/;
            const codeBlockMatch = content.match(codeBlockRegex);
            if (codeBlockMatch && codeBlockMatch[1]) {
              content = codeBlockMatch[1].trim();
            }
            
            analysis = JSON.parse(content);
            feedback = analysis.feedback || feedbackText;
            errors = analysis.grammar_errors || analysis.errors || [];
            
            // L∆∞u th√™m c√°c th√¥ng tin m·ªõi
            analysis.speech_rate = speechRate;
            analysis.missing_words = missingWords; // ƒê·∫£m b·∫£o missing_words lu√¥n ƒë∆∞·ª£c l∆∞u
            analysis.vocabulary_score = analysis.vocabulary_score ? (analysis.vocabulary_score * 10) : 0; // Convert t·ª´ thang 10 sang 100
            analysis.speaking_score = score; // S·ª≠ d·ª•ng ƒëi·ªÉm ƒë√£ t√≠nh t·ª´ ph·∫ßn trƒÉm (thang 100)
          }
          
          // ƒê·∫£m b·∫£o missing_words lu√¥n ƒë∆∞·ª£c l∆∞u v√†o analysis
          if (analysis && (!analysis.missing_words || analysis.missing_words.length === 0)) {
            analysis.missing_words = missingWords;
          } else if (!analysis) {
            analysis = { missing_words: missingWords };
          }
        } catch (err) {
          console.error("‚ùå AI analysis error:", err);
          feedback = "Kh√¥ng th·ªÉ ph√¢n t√≠ch. Vui l√≤ng th·ª≠ l·∫°i.";
        }
      }
    }

    // ƒê·∫£m b·∫£o analysis c√≥ ƒë·∫ßy ƒë·ªß th√¥ng tin, ƒë·∫∑c bi·ªát l√† missing_words
    const finalAnalysis = analysis || {
      feedback,
      grammar_errors: errors,
      speaking_score: score,
      vocabulary_score: 0,
      speech_rate: speechRate,
      missing_words: missingWords
    };
    
    // ƒê·∫£m b·∫£o missing_words lu√¥n c√≥ trong analysis
    if (!finalAnalysis.missing_words || finalAnalysis.missing_words.length === 0) {
      finalAnalysis.missing_words = missingWords;
    }
    
    // C·∫≠p nh·∫≠t database v·ªõi k·∫øt qu·∫£
    await pool.query(
      `UPDATE speaking_practice_rounds 
       SET transcript = $1, score = $2, analysis = $3
       WHERE id = $4`,
      [
        JSON.stringify(transcript),
        finalAnalysis.speaking_score || score,
        JSON.stringify(finalAnalysis),
        roundId
      ]
    );

    console.log("‚úÖ Speaking round processed:", roundId);
  } catch (err) {
    console.error("‚ùå Process speaking round failed:", roundId, err);
  }
});