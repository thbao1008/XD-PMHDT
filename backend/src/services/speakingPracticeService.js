<<<<<<< Current (Your changes)
// backend/src/services/speakingPracticeService.js
import pool from "../config/db.js";
import { runWhisperX } from "../utils/whisperxRunner.js";
import * as learnerAiService from "./learnerAiService.js";
import * as aiService from "./aiService.js";
import * as trainedAIService from "./trainedAIService.js";
import path from "path";
import fs from "fs";

// QUAN TR·ªåNG: Kh√¥ng c√≤n hardcoded prompts
// T·∫•t c·∫£ prompts ƒë∆∞·ª£c generate b·ªüi AI trainer trong ai_models/comprehensiveAITrainer.py
// Training data n·∫±m trong ai_models/promptSamples.json

/**
 * T√≠nh th·ªùi gian d·ª±a tr√™n ƒë·ªô d√†i v√† ƒë·ªô ph·ª©c t·∫°p c·ªßa text
 * D·ª±a tr√™n t·ªëc ƒë·ªô n√≥i c·ªßa ng∆∞·ªùi gi·ªèi ti·∫øng Anh: ~150-200 t·ª´/ph√∫t
 * Th√™m buffer 20% cho ng∆∞·ªùi h·ªçc
 */
function calculateTimeLimit(text, level) {
  if (!text) return 30;
  
  // ƒê·∫øm s·ªë t·ª´
  const words = text.trim().split(/\s+/).length;
  
  // T·ªëc ƒë·ªô n√≥i (t·ª´/gi√¢y)
  // Level 1: 2 t·ª´/gi√¢y (120 t·ª´/ph√∫t) - ch·∫≠m h∆°n
  // Level 2: 2.5 t·ª´/gi√¢y (150 t·ª´/ph√∫t) - trung b√¨nh
  // Level 3: 3 t·ª´/gi√¢y (180 t·ª´/ph√∫t) - nhanh h∆°n
  const wordsPerSecond = level === 1 ? 2 : level === 2 ? 2.5 : 3;
  
  // Th·ªùi gian c∆° b·∫£n
  let baseTime = words / wordsPerSecond;
  
  // Th√™m buffer 20% cho ng∆∞·ªùi h·ªçc
  baseTime = baseTime * 1.2;
  
  // Th√™m th·ªùi gian t·ªëi thi·ªÉu v√† t·ªëi ƒëa
  const minTime = level === 1 ? 15 : level === 2 ? 25 : 35;
  const maxTime = level === 1 ? 45 : level === 2 ? 90 : 120;
  
  return Math.max(minTime, Math.min(maxTime, Math.ceil(baseTime)));
}

/**
 * Kh·ªüi t·∫°o learning t·ª´ c√°c ngu·ªìn (ch·∫°y m·ªôt l·∫ßn khi server start)
 */
export async function initializeAILearning() {
  try {
    // Ki·ªÉm tra xem ƒë√£ h·ªçc ch∆∞a
    const existing = await pool.query(
      `SELECT COUNT(*) as count FROM ai_learning_context LIMIT 1`
    );
    
    if (parseInt(existing.rows[0]?.count || 0) === 0) {
      console.log("ü§ñ Initializing AI learning from available sources...");
      await learnFromAvailableSources();
      console.log("‚úÖ AI learning initialized");
    }
  } catch (err) {
    console.error("‚ùå Error initializing AI learning:", err);
  }
}

/**
 * T·∫°o session m·ªõi cho luy·ªán n√≥i
 */
export async function createPracticeSession(learnerId, level) {
  // ƒê·∫£m b·∫£o AI ƒë√£ h·ªçc t·ª´ c√°c ngu·ªìn
  await initializeAILearning();
  
  const result = await pool.query(
    `INSERT INTO speaking_practice_sessions (learner_id, level, mode, status)
     VALUES ($1, $2, 'practice', 'active')
     RETURNING *`,
    [learnerId, level]
  );
  return result.rows[0];
}

/**
 * T·∫°o session m·ªõi cho Tell me your story
 */
export async function createStorySession(learnerId) {
  const result = await pool.query(
    `INSERT INTO speaking_practice_sessions (learner_id, level, mode, status)
     VALUES ($1, 1, 'story', 'active')
     RETURNING *`,
    [learnerId]
  );
  return result.rows[0];
}

/**
 * AI t·ª± h·ªçc t·ª´ c√°c ngu·ªìn c√≥ s·∫µn (scenarios, topics, etc.)
 */
async function learnFromAvailableSources() {
  try {
    // H·ªçc t·ª´ scenarios
    const scenarios = await pool.query(
      `SELECT id, vocabulary, initial_prompt, difficulty_level 
       FROM speaking_scenarios 
       WHERE vocabulary IS NOT NULL 
       LIMIT 20`
    );

    for (const scenario of scenarios.rows) {
      if (scenario.vocabulary && scenario.initial_prompt) {
        // L∆∞u v√†o learning context
        try {
          // ƒê·∫£m b·∫£o vocabulary l√† JSON h·ª£p l·ªá
          let vocabularyJson = scenario.vocabulary;
          
          // N·∫øu ƒë√£ l√† object (t·ª´ JSONB), convert sang JSON string
          if (typeof vocabularyJson === 'object' && vocabularyJson !== null) {
            vocabularyJson = JSON.stringify(vocabularyJson);
          } else if (typeof vocabularyJson === 'string') {
            // N·∫øu l√† string, ki·ªÉm tra xem c√≥ ph·∫£i JSON h·ª£p l·ªá kh√¥ng
            try {
              JSON.parse(vocabularyJson);
              // N·∫øu parse ƒë∆∞·ª£c, gi·ªØ nguy√™n string
            } catch (e) {
              // N·∫øu kh√¥ng parse ƒë∆∞·ª£c, b·ªè qua vocabulary
              vocabularyJson = null;
            }
          } else {
            vocabularyJson = null;
          }
          
          await pool.query(
            `INSERT INTO ai_learning_context (source_type, source_id, content, vocabulary, level)
             VALUES ('scenario', $1, $2, $3::jsonb, $4)
             ON CONFLICT (source_type, source_id, content) DO NOTHING`,
            [
              scenario.id || null,
              scenario.initial_prompt,
              vocabularyJson,
              scenario.difficulty_level || 1
            ]
          );
        } catch (err) {
          // Ignore duplicate errors v√† conflict errors
          if (!err.message.includes('duplicate') && 
              !err.message.includes('conflict') && 
              err.code !== '23505') {
            console.error("Error inserting learning context:", err.message);
          }
        }
      }
    }

    // QUAN TR·ªåNG: Kh√¥ng c√≤n h·ªçc t·ª´ hardcoded prompts
    // AI s·∫Ω h·ªçc t·ª´ promptSamples.json trong ai_models/comprehensiveAITrainer.py
    // v√† t·ª´ sampleTranscripts.json

    // H·ªçc t·ª´ sampleTranscripts.json n·∫øu c√≥
    try {
      const sampleTranscriptsPath = path.join(process.cwd(), "backend", "ai_models", "sampleTranscripts.json");
      if (fs.existsSync(sampleTranscriptsPath)) {
        const sampleData = JSON.parse(fs.readFileSync(sampleTranscriptsPath, "utf-8"));
        for (const item of sampleData) {
          if (item.topic && item.text) {
            const words = item.text.split(/\s+/).length;
            // X√°c ƒë·ªãnh level d·ª±a tr√™n ƒë·ªô d√†i
            const estimatedLevel = words <= 15 ? 1 : words <= 30 ? 2 : 3;
            
            try {
              await pool.query(
                `INSERT INTO ai_learning_context (source_type, source_id, content, level, metadata)
                 VALUES ('sample_transcripts', NULL, $1, $2, $3)
                 ON CONFLICT (source_type, source_id, content) DO NOTHING`,
                [
                  item.text,
                  estimatedLevel,
                  JSON.stringify({ topic: item.topic, word_count: words, source: 'sampleTranscripts' })
                ]
              );
            } catch (err) {
              // Ignore duplicate errors
              if (!err.message.includes('duplicate') && !err.message.includes('conflict')) {
                console.error("Error inserting sample transcript:", err);
              }
            }
          }
        }
        console.log(`‚úÖ Loaded ${sampleData.length} sample transcripts into learning context`);
      }
    } catch (err) {
      console.error("‚ùå Error loading sampleTranscripts:", err);
    }
  } catch (err) {
    console.error("‚ùå Error learning from sources:", err);
  }
}

// Danh s√°ch topics phong ph√∫ t·ª´ nhi·ªÅu ngu·ªìn
const TOPIC_THEMES = {
  1: [
    "Self-introduction", "Family", "Daily routine", "Food", "Colors", "Numbers", 
    "Weather", "Pets", "School", "Friends", "Hobbies", "Sports", "Shopping",
    "Transportation", "Home", "Clothing", "Body parts", "Time", "Days of week"
  ],
  2: [
    "Travel", "Work", "Education", "Music", "Movies", "Books", "Technology",
    "Health", "Culture", "Future plans", "Dreams", "Art", "Photography",
    "Cooking", "Fitness", "Relationships", "Career", "Language learning",
    "Entertainment", "Social media", "Environment", "Holidays", "Festivals"
  ],
  3: [
    "Artificial Intelligence", "Climate change", "Globalization", "Philosophy",
    "Psychology", "Economics", "Politics", "Science", "Research", "Innovation",
    "Sustainability", "Ethics", "Society", "History", "Literature", "Mathematics",
    "Physics", "Chemistry", "Biology", "Astronomy", "Cybersecurity", "Data science",
    "Machine learning", "AI ethics", "Public health", "Mental health", "Nutrition"
  ]
};

/**
 * L·∫•y topics v√† prompts ƒë√£ d√πng trong session ƒë·ªÉ tr√°nh l·∫∑p l·∫°i
 */
async function getUsedTopicsInSession(sessionId, level) {
  try {
    if (!sessionId) return { topics: [], prompts: [] };
    
    const usedRounds = await pool.query(
      `SELECT spr.prompt, agp.topic 
       FROM speaking_practice_rounds spr
       LEFT JOIN ai_generated_prompts agp ON spr.prompt = agp.prompt_text
       WHERE spr.session_id = $1
       ORDER BY spr.round_number DESC
       LIMIT 10`,
      [sessionId]
    );
    
    const topics = usedRounds.rows.map(r => r.topic).filter(Boolean);
    const prompts = usedRounds.rows.map(r => r.prompt).filter(Boolean);
    
    return { topics, prompts };
  } catch (err) {
    console.error("Error getting used topics:", err);
    return { topics: [], prompts: [] };
  }
}

/**
 * G·ªçi Python continuous learning engine ƒë·ªÉ ph√¢n t√≠ch v√† c√° nh√¢n h√≥a
 */
async function getPersonalizationContext(learnerId, sessionId) {
  try {
    const { exec } = await import("child_process");
    const { promisify } = await import("util");
    const execAsync = promisify(exec);
    
    const enginePath = path.join(process.cwd(), "backend", "ai_models", "continuousLearningEngine.py");
    
    // L·∫•y d·ªØ li·ªáu session ƒë·ªÉ ph√¢n t√≠ch
    const rounds = await pool.query(
      `SELECT score, prompt, time_taken, analysis 
       FROM speaking_practice_rounds 
       WHERE session_id = $1 AND score > 0
       ORDER BY round_number`,
      [sessionId]
    );
    
    if (rounds.rows.length === 0) {
      return null;
    }
    
    // Chu·∫©n b·ªã data cho continuous learning
    const sessionData = {
      scores: rounds.rows.map(r => parseFloat(r.score) || 0),
      topics: rounds.rows.map(r => {
        try {
          const analysis = typeof r.analysis === 'string' ? JSON.parse(r.analysis) : r.analysis;
          return analysis?.topic || 'general';
        } catch {
          return 'general';
        }
      }),
      durations: rounds.rows.map(r => parseInt(r.time_taken) || 0),
      strengths: rounds.rows.map(r => {
        try {
          const analysis = typeof r.analysis === 'string' ? JSON.parse(r.analysis) : r.analysis;
          return analysis?.strengths || [];
        } catch {
          return [];
        }
      }),
      improvements: rounds.rows.map(r => {
        try {
          const analysis = typeof r.analysis === 'string' ? JSON.parse(r.analysis) : r.analysis;
          return analysis?.improvements || [];
        } catch {
          return [];
        }
      })
    };
    
    const sessionDataJson = JSON.stringify(sessionData).replace(/"/g, '\\"');
    const command = `python "${enginePath}" analyze ${learnerId} "${sessionDataJson}"`;
    
    const { stdout } = await execAsync(command);
    const result = JSON.parse(stdout);
    
    // L·∫•y personalization context t·ª´ k·∫øt qu·∫£
    const personalization = result.personalization_context || {};
    const analysis = result.analysis || {};
    
    // T·∫°o personalization context t·ª´ analysis
    return {
      recommended_level: analysis.adaptive_strategy?.recommended_level || personalization.recommended_level,
      preferred_topics: analysis.strength_areas?.top_strengths || personalization.preferred_topics || [],
      focus_areas: analysis.improvement_areas?.priority_improvements || personalization.focus_areas || [],
      learning_style: analysis.adaptive_strategy?.learning_style || personalization.learning_style || 'balanced',
      pace: analysis.adaptive_strategy?.pace_adjustment || personalization.pace || 'normal'
    };
  } catch (err) {
    console.error("‚ùå Error getting personalization context:", err);
    return null;
  }
}

/**
 * G·ªçi Python comprehensive trainer ƒë·ªÉ t·∫°o training data th√¥ng minh
 */
async function getTrainingDataFromPython(trainingType, options = {}) {
  return new Promise(async (resolve) => {
    try {
      const { spawn } = await import("child_process");
      const trainerPath = path.join(process.cwd(), "backend", "ai_models", "comprehensiveAITrainer.py");
      
      // T·∫°o data object ƒë·ªÉ g·ª≠i qua stdin
      let stdinData = { training_type: trainingType };
      
      if (trainingType === 'prompt_generator') {
        // L·∫•y topics v√† challenges t·ª´ database
        const topics = await pool.query(`SELECT id, title, description, level FROM topics ORDER BY RANDOM() LIMIT 20`);
        const challenges = await pool.query(`SELECT id, title, description, level, topic_id, type FROM challenges ORDER BY RANDOM() LIMIT 20`);
        
        const topicsJson = JSON.stringify(topics.rows);
        const challengesJson = JSON.stringify(challenges.rows);
        
        // L·∫•y personalization context n·∫øu c√≥ learnerId
        let personalizationContext = null;
        if (options.learnerId && options.sessionId) {
          personalizationContext = await getPersonalizationContext(options.learnerId, options.sessionId);
        }
        
        stdinData = {
          training_type: 'prompt_generator',
          level: options.level || 2,
          used_topics: options.usedTopics || [],
          used_prompts: options.usedPrompts || [],
          topics_json: topicsJson,
          challenges_json: challengesJson,
          learner_id: options.learnerId || null,
          personalization_context: personalizationContext
        };
      } else if (trainingType === 'conversation_ai') {
        stdinData = {
          training_type: 'conversation_ai',
          topic: options.topic || null,
          history: options.history || []
        };
      } else if (trainingType === 'quick_analysis') {
        stdinData = {
          training_type: 'quick_analysis',
          transcript: options.transcript || "",
          expected: options.expected || null,
          level: options.level || 2
        };
      }
      
<<<<<<< Current (Your changes)
      // Spawn Python process v·ªõi stdin
      const pythonProcess = spawn('python', [trainerPath], {
        stdio: ['pipe', 'pipe', 'pipe'],
        shell: true
=======
      // Spawn Python process v·ªõi stdin v√† set UTF-8 encoding
      const pythonProcess = spawn('python', [trainerPath], {
        stdio: ['pipe', 'pipe', 'pipe'],
        shell: true,
        env: {
          ...process.env,
          PYTHONIOENCODING: 'utf-8'
        }
>>>>>>> Incoming (Background Agent changes)
      });
      
      let stdout = '';
      let stderr = '';
      
      pythonProcess.stdout.on('data', (data) => {
        stdout += data.toString();
      });
      
      pythonProcess.stderr.on('data', (data) => {
        stderr += data.toString();
      });
      
      pythonProcess.on('close', (code) => {
        if (code !== 0) {
          console.error("‚ùå Python trainer error:", stderr);
          resolve(null); // Return null ƒë·ªÉ fallback
          return;
        }
        
        try {
          const result = JSON.parse(stdout);
          resolve(result);
        } catch (err) {
          console.error("‚ùå Error parsing Python output:", err);
          console.error("Python stdout:", stdout);
          resolve(null); // Return null ƒë·ªÉ fallback
        }
      });
      
      pythonProcess.on('error', (err) => {
        console.error("‚ùå Error spawning Python process:", err);
        resolve(null); // Return null ƒë·ªÉ fallback
      });
      
      // G·ª≠i data qua stdin
      pythonProcess.stdin.write(JSON.stringify(stdinData));
      pythonProcess.stdin.end();
      
    } catch (err) {
      console.error("‚ùå Error calling Python trainer:", err);
      resolve(null); // Return null ƒë·ªÉ fallback
    }
  });
}

/**
 * AI t·ª± t·∫°o prompt m·ªõi s·ª≠ d·ª•ng Python trainer (ƒë∆°n gi·∫£n h√≥a)
 */
async function generateAIPrompt(level, roundNumber, learnerId = null, sessionId = null) {
  try {
    // L·∫•y topics v√† prompts ƒë√£ d√πng trong session ƒë·ªÉ tr√°nh l·∫∑p l·∫°i
    const { topics: usedTopics, prompts: usedPrompts } = await getUsedTopicsInSession(sessionId, level);
    
    // L·∫•y personalization context t·ª´ continuous learning engine
    let personalizationContext = null;
    if (learnerId && sessionId) {
      personalizationContext = await getPersonalizationContext(learnerId, sessionId);
    }
    
    // L·∫•y topics v√† challenges t·ª´ database v·ªõi randomization TR∆Ø·ªöC khi g·ªçi trainer
    const topics = await pool.query(`SELECT id, title, description, level FROM topics ORDER BY RANDOM() LIMIT 20`);
    const challenges = await pool.query(`SELECT id, title, description, level, topic_id, type FROM challenges ORDER BY RANDOM() LIMIT 20`);
    
    // G·ªçi OpenRouter v·ªõi training data t·ª´ Python qua trainedAIService
    // trainedAIService s·∫Ω t·ª± ƒë·ªông g·ªçi Python trainer v·ªõi topics/challenges
    const response = await trainedAIService.callTrainedAI(
      'prompt_generator',
      {
        level,
        usedTopics,
        usedPrompts,
        learnerId,
        sessionId,
        topicsJson: JSON.stringify(topics.rows),
        challengesJson: JSON.stringify(challenges.rows),
        personalizationContext
      },
      null, // Messages s·∫Ω ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông v·ªõi randomization
      { 
        model: 'openai/gpt-4o-mini', 
        temperature: 1.1, // Temperature cao ƒë·ªÉ ƒë·∫£m b·∫£o ƒëa d·∫°ng
        max_tokens: 250 
      }
    );
    
    // N·∫øu response fail, fallback
    if (!response || !response.choices || !response.choices[0]) {
      console.warn("‚ö†Ô∏è AI response failed, using fallback");
      return await generateAIPromptFallback(level, usedTopics, usedPrompts);
    }

    const content = response.choices?.[0]?.message?.content || "{}";
    let result;
    try {
      result = JSON.parse(content);
    } catch (e) {
      // N·∫øu kh√¥ng ph·∫£i JSON, extract
      const promptMatch = content.match(/"suggested_prompt":\s*"([^"]+)"/);
      const topicMatch = content.match(/"topic":\s*"([^"]+)"/);
      result = {
        topic: topicMatch ? topicMatch[1] : usedTopics[0] || "general",
        suggested_prompt: promptMatch ? promptMatch[1] : content.trim().replace(/^["']|["']$/g, ""),
        description: ""
      };
    }

    // S·ª≠ d·ª•ng suggested_prompt ho·∫∑c t·∫°o prompt t·ª´ topic
    const finalPrompt = result.suggested_prompt || result.prompt || 
      `Let's talk about ${result.topic || 'something interesting'}.`;

    if (!finalPrompt) {
      throw new Error("Failed to generate prompt");
    }

    // L∆∞u prompt ƒë√£ generate v√†o database
    const wordCount = finalPrompt.split(/\s+/).length;
    const difficultyScore = level === 1 ? 0.3 : level === 2 ? 0.6 : 0.9;

    await pool.query(
      `INSERT INTO ai_generated_prompts 
       (level, prompt_text, topic, word_count, difficulty_score, usage_count)
       VALUES ($1, $2, $3, $4, $5, 1)
       ON CONFLICT (prompt_text) DO UPDATE 
       SET usage_count = ai_generated_prompts.usage_count + 1, 
           last_used_at = NOW(),
           updated_at = NOW()`,
      [
        level,
        finalPrompt,
        result.topic || "general",
        wordCount,
        difficultyScore
      ]
    );

    return finalPrompt;
  } catch (err) {
    console.error("‚ùå Error generating AI prompt:", err);
    // Fallback v·ªÅ prompts c≈© n·∫øu AI fail
    // Fallback: Generate simple prompt with AI
    const fallbackPrompt = `Generate a simple English speaking practice sentence for level ${level} learners. Return only the sentence, no explanation.`;
    try {
      const response = await aiService.callOpenRouter(
        [{ role: "user", content: fallbackPrompt }],
        { model: "openai/gpt-4o-mini", temperature: 1.0, max_tokens: 100 }
      );
      const content = response.choices?.[0]?.message?.content || "";
      return content.trim().replace(/^["']|["']$/g, "") || `Let's practice speaking English. This is level ${level}.`;
    } catch (fallbackErr) {
      const ultimateFallback = {
        1: "Hello, my name is Anna. I am from Vietnam.",
        2: "I enjoy learning English because it helps me communicate with people from different countries.",
        3: "The advancement of technology has significantly transformed how we learn and interact with information in the modern world."
      };
      return ultimateFallback[level] || ultimateFallback[1];
    }
  }
}

/**
 * Fallback method n·∫øu Python trainer kh√¥ng ho·∫°t ƒë·ªông (ƒë∆°n gi·∫£n h√≥a)
 */
async function generateAIPromptFallback(level, usedTopics = [], usedPrompts = []) {
  // ƒê∆°n gi·∫£n h√≥a: ch·ªâ t·∫°o prompt ng·∫Øn g·ªçn v·ªõi AI
  const availableTopics = TOPIC_THEMES[level] || TOPIC_THEMES[1];
  const unusedTopics = availableTopics.filter(t => !usedTopics.includes(t));
  const selectedTopics = unusedTopics.length > 0 
    ? unusedTopics.sort(() => Math.random() - 0.5).slice(0, 3)
    : availableTopics.sort(() => Math.random() - 0.5).slice(0, 3);
  
  const simplePrompt = `Generate a NEW speaking practice sentence for level ${level} English learners.
- Length: ${level === 1 ? '5-15' : level === 2 ? '15-30' : '30-60'} words
- Topic: ${selectedTopics.join(' or ')}
- Avoid: ${usedPrompts.slice(0, 3).join(', ') || 'none'}
- Natural, conversational English

Return JSON: {"prompt": "sentence", "topic": "topic name", "word_count": number}`;

  const response = await aiService.callOpenRouter(
    [{ role: "user", content: simplePrompt }],
    { model: "openai/gpt-4o-mini", temperature: 0.95, max_tokens: 200 }
  );

  const content = response.choices?.[0]?.message?.content || "{}";
  let result;
  try {
    result = JSON.parse(content);
  } catch (e) {
    result = {
      prompt: content.trim().replace(/^["']|["']$/g, ""),
      topic: selectedTopics[0] || "general",
      word_count: content.split(/\s+/).length
    };
  }

  // N·∫øu v·∫´n fail, t·∫°o prompt ƒë∆°n gi·∫£n nh·∫•t
  if (!result.prompt) {
    const levelPrompts = {
      1: "Hello, my name is Anna. I am from Vietnam.",
      2: "I enjoy learning English because it helps me communicate with people from different countries.",
      3: "The advancement of technology has significantly transformed how we learn and interact with information in the modern world."
    };
    return levelPrompts[level] || levelPrompts[1];
  }
  
  return result.prompt;
}

/**
 * L·∫•y prompt cho v√≤ng n√≥i (∆∞u ti√™n AI-generated, ƒëa d·∫°ng h√≥a)
 * QUAN TR·ªåNG: Lu√¥n t·∫°o prompt M·ªöI, kh√¥ng reuse prompts ƒë√£ d√πng trong session
 */
export async function getPromptForRound(level, roundNumber, learnerId = null, sessionId = null) {
  try {
    console.log(`üéØ getPromptForRound called: level=${level}, round=${roundNumber}, sessionId=${sessionId}`);
    
    // L·∫•y topics v√† prompts ƒë√£ d√πng trong session
    const { topics: usedTopics, prompts: usedPrompts } = await getUsedTopicsInSession(sessionId, level);
    console.log(`üìã Used in session: ${usedPrompts.length} prompts, ${usedTopics.length} topics`);
    
    // QUAN TR·ªåNG: Lu√¥n generate prompt M·ªöI thay v√¨ l·∫•y t·ª´ database
    // ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o m·ªói round c√≥ prompt kh√°c nhau
    console.log(`üîÑ Generating NEW prompt for round ${roundNumber}...`);
    const newPrompt = await generateAIPrompt(level, roundNumber, learnerId, sessionId);
    
    // Ki·ªÉm tra xem prompt m·ªõi c√≥ tr√πng v·ªõi prompts ƒë√£ d√πng kh√¥ng
    if (usedPrompts.includes(newPrompt)) {
      console.warn(`‚ö†Ô∏è Generated prompt matches used prompt, generating again...`);
      // Generate l·∫°i n·∫øu tr√πng
      const retryPrompt = await generateAIPrompt(level, roundNumber, learnerId, sessionId);
      return retryPrompt;
    }
    
    console.log(`‚úÖ Generated new prompt: "${newPrompt.substring(0, 50)}..."`);
    return newPrompt;
    
    /* OLD LOGIC - Commented out ƒë·ªÉ lu√¥n generate m·ªõi
    // Th·ª≠ l·∫•y t·ª´ AI-generated prompts v·ªõi ∆∞u ti√™n topics ch∆∞a d√πng v√† prompts ch∆∞a d√πng
    let aiPrompt;
    if (usedPrompts.length > 0) {
      // N·∫øu c√≥ prompts ƒë√£ d√πng, lo·∫°i b·ªè ch√∫ng
      aiPrompt = await pool.query(
        `SELECT prompt_text, topic FROM ai_generated_prompts 
         WHERE level = $1 
         AND prompt_text NOT IN (${usedPrompts.map((_, i) => `$${i + 2}`).join(", ")})
         ${usedTopics.length > 0 
           ? `AND (topic NOT IN (${usedTopics.map((_, i) => `$${usedPrompts.length + i + 2}`).join(", ")}) OR topic IS NULL)`
           : ""}
         ORDER BY 
           ${usedTopics.length > 0 
             ? `CASE WHEN topic NOT IN (${usedTopics.map((_, i) => `$${usedPrompts.length + i + 2}`).join(", ")}) THEN 0 ELSE 1 END, `
             : ""}
           usage_count ASC, 
           RANDOM()
         LIMIT 1`,
        [level, ...usedPrompts, ...usedTopics]
      );
    } else if (usedTopics.length > 0) {
      // Ch·ªâ c√≥ topics ƒë√£ d√πng
      aiPrompt = await pool.query(
        `SELECT prompt_text, topic FROM ai_generated_prompts 
         WHERE level = $1 
         AND (topic NOT IN (${usedTopics.map((_, i) => `$${i + 2}`).join(", ")}) OR topic IS NULL)
         ORDER BY 
           CASE WHEN topic NOT IN (${usedTopics.map((_, i) => `$${i + 2}`).join(", ")}) THEN 0 ELSE 1 END,
           usage_count ASC, 
           RANDOM()
         LIMIT 1`,
        [level, ...usedTopics]
      );
    } else {
      // Ch∆∞a c√≥ g√¨ ƒë∆∞·ª£c d√πng
      aiPrompt = await pool.query(
        `SELECT prompt_text, topic FROM ai_generated_prompts 
         WHERE level = $1 
         ORDER BY usage_count ASC, RANDOM()
         LIMIT 1`,
        [level]
      );
    }

    // N·∫øu kh√¥ng t√¨m th·∫•y prompt v·ªõi topic m·ªõi, t√¨m b·∫•t k·ª≥
    let selectedPrompt = aiPrompt.rows[0];
    if (!selectedPrompt) {
      const anyPrompt = await pool.query(
        `SELECT prompt_text, topic FROM ai_generated_prompts 
         WHERE level = $1 
         ORDER BY usage_count ASC, RANDOM() 
         LIMIT 1`,
        [level]
      );
      selectedPrompt = anyPrompt.rows[0];
    }

    if (selectedPrompt) {
      // Update usage
      await pool.query(
        `UPDATE ai_generated_prompts 
         SET usage_count = usage_count + 1, last_used_at = NOW()
         WHERE prompt_text = $1`,
        [selectedPrompt.prompt_text]
      );
      return selectedPrompt.prompt_text;
    }

    // N·∫øu ch∆∞a c√≥, generate m·ªõi v·ªõi ƒëa d·∫°ng h√≥a
    return await generateAIPrompt(level, roundNumber, learnerId, sessionId);
    */
  } catch (err) {
    console.error("‚ùå Error getting prompt:", err);
    // Fallback cu·ªëi c√πng: t·∫°o prompt ƒë∆°n gi·∫£n v·ªõi AI tr·ª±c ti·∫øp
    try {
      const fallbackPrompt = `Generate a simple English speaking practice sentence for level ${level} learners. Return only the sentence, no explanation.`;
      const response = await aiService.callOpenRouter(
        [{ role: "user", content: fallbackPrompt }],
        { model: "openai/gpt-4o-mini", temperature: 1.0, max_tokens: 100 }
      );
      const content = response.choices?.[0]?.message?.content || "";
      return content.trim().replace(/^["']|["']$/g, "") || `Let's practice speaking English. This is level ${level}.`;
    } catch (fallbackErr) {
      console.error("‚ùå Fallback prompt generation failed:", fallbackErr);
      // Ultimate fallback - simple prompts
      const ultimateFallback = {
        1: "Hello, my name is Anna. I am from Vietnam.",
        2: "I enjoy learning English because it helps me communicate with people from different countries.",
        3: "The advancement of technology has significantly transformed how we learn and interact with information in the modern world."
      };
      return ultimateFallback[level] || ultimateFallback[1];
    }
  }
}

/**
 * L·∫•y time limit cho level v√† prompt
 */
export function getTimeLimit(level, prompt = "") {
  return calculateTimeLimit(prompt, level);
}

/**
 * L∆∞u v√≤ng n√≥i (l∆∞u ngay, x·ª≠ l√Ω ·ªü background)
 */
export async function saveRound(sessionId, roundNumber, audioUrl, timeTaken, promptText = null) {
  const session = await pool.query(
    `SELECT level, learner_id FROM speaking_practice_sessions WHERE id = $1`,
    [sessionId]
  );

  if (!session.rows[0]) {
    throw new Error("Session not found");
  }

  const level = session.rows[0].level;
  const learnerId = session.rows[0].learner_id;
  
  // QUAN TR·ªåNG: N·∫øu promptText ƒë∆∞·ª£c truy·ªÅn t·ª´ frontend, d√πng n√≥. N·∫øu kh√¥ng, fetch m·ªõi
  let prompt = promptText;
  if (!prompt) {
    // Fetch prompt m·ªõi v·ªõi sessionId ƒë·ªÉ track used prompts
    prompt = await getPromptForRound(level, roundNumber, learnerId, sessionId);
  }

  // L∆∞u v√†o database ngay (ch∆∞a c√≥ transcript v√† analysis)
  const result = await pool.query(
    `INSERT INTO speaking_practice_rounds 
     (session_id, round_number, prompt, audio_url, transcript, time_taken, score, analysis)
     VALUES ($1, $2, $3, $4, NULL, $5, 0, NULL)
     RETURNING *`,
    [
      sessionId,
      roundNumber,
      prompt,
      audioUrl,
      timeTaken
    ]
  );

  const roundId = result.rows[0].id;

  // Enqueue job ƒë·ªÉ x·ª≠ l√Ω transcription v√† analysis ·ªü background
  try {
    const { enqueue } = await import("../utils/queue.js");
    await enqueue("processSpeakingRound", {
      roundId,
      sessionId,
      audioUrl,
      prompt,
      level,
      time_taken: timeTaken
    });
  } catch (err) {
    console.error("‚ùå Error enqueueing processing job:", err);
    // N·∫øu kh√¥ng c√≥ queue, x·ª≠ l√Ω ngay (fallback)
    processRoundInBackground(roundId, audioUrl, prompt, level).catch(err => {
      console.error("‚ùå Background processing error:", err);
    });
  }

  return result.rows[0];
}

/**
 * X·ª≠ l√Ω round ·ªü background (transcription + AI analysis)
 */
async function processRoundInBackground(roundId, audioUrl, prompt, level) {
  const localPath = audioUrl.startsWith("/uploads/")
    ? path.join(process.cwd(), audioUrl)
    : audioUrl;

  let transcript = null;
  if (fs.existsSync(localPath)) {
    try {
      const { json: transcriptJson } = await runWhisperX(localPath, {
        model: "base",
        computeType: "float32"
      });
      transcript = transcriptJson;
    } catch (err) {
      console.error("‚ùå Transcription error:", err);
      return;
    }
  }

  // Analyze v·ªõi AI
  let analysis = null;
  let score = 0;
  let feedback = "";
  let errors = [];
  let correctedText = "";

  if (transcript) {
    const transcriptText =
      transcript.text ||
      (transcript.segments || [])
        .map((s) => s.text || "")
        .join(" ");

    try {
      analysis = await analyzePronunciation(transcriptText, prompt, level);
      score = analysis.score || 0;
      feedback = analysis.feedback || "";
      errors = analysis.errors || [];
      correctedText = analysis.corrected_text || "";
    } catch (err) {
      console.error("‚ùå AI analysis error:", err);
      feedback = "Kh√¥ng th·ªÉ ph√¢n t√≠ch. Vui l√≤ng th·ª≠ l·∫°i.";
    }
  }

  // C·∫≠p nh·∫≠t database v·ªõi k·∫øt qu·∫£
  await pool.query(
    `UPDATE speaking_practice_rounds 
     SET transcript = $1, score = $2, analysis = $3
     WHERE id = $4`,
    [
      JSON.stringify(transcript),
      score,
      JSON.stringify({
        feedback,
        errors,
        corrected_text: correctedText,
        score
      }),
      roundId
    ]
  );
}

/**
 * Ph√¢n t√≠ch ph√°t √¢m v·ªõi AI s·ª≠ d·ª•ng Python trainer (quick analysis)
 */
async function analyzePronunciation(transcript, expectedText, level, roundId = null, sessionId = null, learnerId = null) {
  try {
    // G·ªçi Python trainer ƒë·ªÉ t·∫°o quick analysis training
    const trainingData = await getTrainingDataFromPython('quick_analysis', {
      transcript,
      expected: expectedText,
      level
    });
    
    // N·∫øu Python trainer fail, d√πng fallback
    if (!trainingData || !trainingData.system_prompt) {
      return await analyzePronunciationFallback(transcript, expectedText, level);
    }
    
    // G·ªçi OpenRouter v·ªõi training data t·ª´ Python qua trainedAIService
    const messages = [
      { role: 'user', content: 'Analyze now. Return JSON only.' }
    ];
    
    const response = await trainedAIService.callTrainedAI(
      'quick_analysis',
      {
        transcript,
        expected: expectedText,
        level
      },
      messages,
      { model: 'openai/gpt-4o-mini', temperature: 0.5, max_tokens: 200 }
    );

    const content = response.choices?.[0]?.message?.content || "{}";
    let parsed;
    try {
      parsed = JSON.parse(content);
    } catch (e) {
      return await analyzePronunciationFallback(transcript, expectedText, level);
    }
    
    // L∆∞u quick evaluation v√†o database
    if (roundId && learnerId) {
      await pool.query(
        `INSERT INTO quick_evaluations 
         (round_id, session_id, learner_id, score, feedback, strengths, improvements)
         VALUES ($1, $2, $3, $4, $5, $6, $7)`,
        [
          roundId,
          sessionId,
          learnerId,
          parsed.score || 5,
          parsed.feedback || "",
          JSON.stringify(parsed.strengths || []),
          JSON.stringify(parsed.improvements || [])
        ]
      );
    }
    
    return {
      score: parsed.score || 5,
      feedback: parsed.feedback || "Good effort!",
      errors: [],
      corrected_text: expectedText,
      strengths: parsed.strengths || [],
      improvements: parsed.improvements || []
    };
  } catch (err) {
    console.error("‚ùå AI analysis error:", err);
    return await analyzePronunciationFallback(transcript, expectedText, level);
  }
}

/**
 * Fallback cho pronunciation analysis
 */
async function analyzePronunciationFallback(transcript, expectedText, level) {
  const prompt = `Quick analysis. Expected: "${expectedText}". Spoken: "${transcript}". 
Return JSON: {"score": 0-10, "feedback": "brief", "strengths": ["s1"], "improvements": ["i1"]}`;

  try {
    const response = await aiService.callOpenRouter(
      [{ role: "user", content: prompt }],
      { model: "openai/gpt-4o-mini", temperature: 0.5, max_tokens: 200 }
    );

    const content = response.choices?.[0]?.message?.content || "{}";
    const parsed = JSON.parse(content);
    return {
      score: parsed.score || 5,
      feedback: parsed.feedback || "Good effort!",
      errors: [],
      corrected_text: expectedText,
      strengths: parsed.strengths || [],
      improvements: parsed.improvements || []
    };
  } catch (err) {
    return {
      score: 5,
      feedback: "Kh√¥ng th·ªÉ ph√¢n t√≠ch chi ti·∫øt.",
      errors: [],
      corrected_text: expectedText,
      strengths: [],
      improvements: []
    };
  }
}

/**
 * Ph√¢n t√≠ch t·∫•t c·∫£ c√°c v√≤ng v√† t·∫°o t·ªïng k·∫øt
 */
export async function analyzeAllRoundsAndSummary(sessionId) {
  // L·∫•y t·∫•t c·∫£ c√°c rounds ch∆∞a ƒë∆∞·ª£c ph√¢n t√≠ch
  const rounds = await pool.query(
    `SELECT * FROM speaking_practice_rounds 
     WHERE session_id = $1 
     ORDER BY round_number`,
    [sessionId]
  );

  if (rounds.rows.length === 0) {
    throw new Error("No rounds found");
  }

  // L·∫•y level t·ª´ session
  const session = await pool.query(
    `SELECT level FROM speaking_practice_sessions WHERE id = $1`,
    [sessionId]
  );
  const level = session.rows[0]?.level || 1;

  // Ph√¢n t√≠ch t·ª´ng round ch∆∞a ƒë∆∞·ª£c ph√¢n t√≠ch (x·ª≠ l√Ω song song ƒë·ªÉ nhanh h∆°n)
  const roundsToProcess = rounds.rows.filter(r => {
    if (r.analysis && r.score > 0) return false;
    if (!r.audio_url) return false;
    const localPath = r.audio_url.startsWith("/uploads/")
      ? path.join(process.cwd(), r.audio_url)
      : r.audio_url;
    return fs.existsSync(localPath);
  });

  // X·ª≠ l√Ω song song t·ªëi ƒëa 3 rounds c√πng l√∫c ƒë·ªÉ tƒÉng t·ªëc
  const processRound = async (round) => {
    const audioUrl = round.audio_url;
    const localPath = audioUrl.startsWith("/uploads/")
      ? path.join(process.cwd(), audioUrl)
      : audioUrl;

    // Transcribe
    let transcript = null;
    try {
      const { json: transcriptJson } = await runWhisperX(localPath, {
        model: "base",
        computeType: "float32"
      });
      transcript = transcriptJson;
    } catch (err) {
      console.error(`‚ùå Transcription error for round ${round.round_number}:`, err);
      return;
    }

    // Analyze v·ªõi AI
    let analysis = null;
    let score = 0;
    let feedback = "";
    let errors = [];
    let correctedText = "";

    if (transcript) {
      const transcriptText =
        transcript.text ||
        (transcript.segments || [])
          .map((s) => s.text || "")
          .join(" ");

      try {
        // L·∫•y learner_id t·ª´ session
        const sessionInfo = await pool.query(
          `SELECT learner_id FROM speaking_practice_sessions WHERE id = $1`,
          [sessionId]
        );
        const learnerId = sessionInfo.rows[0]?.learner_id;
        
        // S·ª≠ d·ª•ng quick analysis v·ªõi Python trainer
        analysis = await analyzePronunciation(
          transcriptText, 
          round.prompt, 
          level,
          round.id, // roundId
          sessionId,
          learnerId
        );
        score = analysis.score || 0;
        feedback = analysis.feedback || "";
        errors = analysis.errors || [];
        correctedText = analysis.corrected_text || "";
      } catch (err) {
        console.error(`‚ùå AI analysis error for round ${round.round_number}:`, err);
        feedback = "Kh√¥ng th·ªÉ ph√¢n t√≠ch. Vui l√≤ng th·ª≠ l·∫°i.";
      }
    }

    // C·∫≠p nh·∫≠t database v·ªõi k·∫øt qu·∫£
    await pool.query(
      `UPDATE speaking_practice_rounds 
       SET transcript = $1, score = $2, analysis = $3
       WHERE id = $4`,
      [
        JSON.stringify(transcript),
        score,
        JSON.stringify({
          feedback,
          errors,
          corrected_text: correctedText,
          score
        }),
        round.id
      ]
    );
  };

  // X·ª≠ l√Ω song song v·ªõi batch size = 3
  const batchSize = 3;
  for (let i = 0; i < roundsToProcess.length; i += batchSize) {
    const batch = roundsToProcess.slice(i, i + batchSize);
    await Promise.all(batch.map(round => processRound(round)));
  }

  // Sau khi ph√¢n t√≠ch xong, t·∫°o summary
  return await generateSummary(sessionId);
}

/**
 * T·∫°o t·ªïng k·∫øt sau 10 v√≤ng
 */
export async function generateSummary(sessionId) {
  const rounds = await pool.query(
    `SELECT * FROM speaking_practice_rounds 
     WHERE session_id = $1 
     ORDER BY round_number`,
    [sessionId]
  );

  if (rounds.rows.length === 0) {
    throw new Error("No rounds found");
  }

  const totalScore = rounds.rows.reduce((sum, r) => sum + (parseFloat(r.score) || 0), 0);
  const averageScore = totalScore / rounds.rows.length;

  // T·∫°o t·ªïng k·∫øt v·ªõi AI (t·ªëi ∆∞u cho t·ªëc ƒë·ªô)
  const summaryPrompt = `Summary: ${rounds.rows.length} rounds, avg ${averageScore.toFixed(1)}/10.
Scores: ${rounds.rows.map((r, i) => `R${i+1}:${r.score}`).join(" ")}.

Return JSON only:
{"overall_feedback": "brief", "common_mistakes": ["m1"], "strengths": ["s1"], "improvements": ["i1"], "encouragement": "brief"}`;

  let summaryData = {
    overall_feedback: "Good effort! Keep practicing.",
    common_mistakes: [],
    strengths: [],
    improvements: [],
    encouragement: "You're making progress!"
  };

  try {
    const response = await aiService.callOpenRouter(
      [{ role: "user", content: summaryPrompt }],
      { 
        model: "openai/gpt-4o-mini", 
        temperature: 0.5, // Gi·∫£m temperature
        max_tokens: 400 // Gi·∫£m max_tokens
      }
    );

    const content = response.choices?.[0]?.message?.content || "{}";
    summaryData = JSON.parse(content);
  } catch (err) {
    console.error("‚ùå Summary generation error:", err);
  }

  // Update session
  await pool.query(
    `UPDATE speaking_practice_sessions 
     SET status = 'completed',
         total_score = $1,
         average_score = $2,
         summary = $3,
         completed_at = NOW()
     WHERE id = $4`,
    [totalScore, averageScore, JSON.stringify(summaryData), sessionId]
  );

  // L∆∞u v√†o practice_history ƒë·ªÉ tracking ti·∫øn ƒë·ªô
  const sessionInfo = await pool.query(
    `SELECT learner_id, level, created_at, completed_at 
     FROM speaking_practice_sessions 
     WHERE id = $1`,
    [sessionId]
  );
  
  if (sessionInfo.rows[0]) {
    const session = sessionInfo.rows[0];
    const duration = session.completed_at && session.created_at
      ? Math.round((new Date(session.completed_at) - new Date(session.created_at)) / 60000)
      : null;
    
    // L·∫•y strengths v√† improvements t·ª´ quick evaluations
    const evaluations = await pool.query(
      `SELECT strengths, improvements FROM quick_evaluations 
       WHERE session_id = $1`,
      [sessionId]
    );
    
    const allStrengths = [];
    const allImprovements = [];
    evaluations.rows.forEach(e => {
      if (e.strengths) {
        try {
          const s = typeof e.strengths === 'string' ? JSON.parse(e.strengths) : e.strengths;
          if (Array.isArray(s)) allStrengths.push(...s);
        } catch {}
      }
      if (e.improvements) {
        try {
          const i = typeof e.improvements === 'string' ? JSON.parse(e.improvements) : e.improvements;
          if (Array.isArray(i)) allImprovements.push(...i);
        } catch {}
      }
    });
    
    // L∆∞u practice history
    await pool.query(
      `INSERT INTO practice_history 
       (learner_id, session_id, practice_type, level, total_score, average_score, 
        evaluation, strengths, improvements, duration_minutes)
       VALUES ($1, $2, 'speaking_practice', $3, $4, $5, $6, $7, $8, $9)`,
      [
        session.learner_id,
        sessionId,
        session.level,
        totalScore,
        averageScore,
        summaryData.overall_feedback || "Good practice session!",
        JSON.stringify([...new Set(allStrengths)].slice(0, 3)),
        JSON.stringify([...new Set(allImprovements)].slice(0, 3)),
        duration
      ]
    );
  }

  return {
    total_score: totalScore,
    average_score: averageScore,
    ...summaryData
  };
}

/**
 * X·ª≠ l√Ω message trong story mode
 */
export async function processStoryMessage(sessionId, text, audioUrl) {
  let transcript = null;
  let transcriptText = "";

  // N·∫øu c√≥ audio, transcribe
  if (audioUrl) {
    const localPath = audioUrl.startsWith("/uploads/")
      ? path.join(process.cwd(), audioUrl)
      : audioUrl;

    if (fs.existsSync(localPath)) {
      try {
        const { json: transcriptJson } = await runWhisperX(localPath, {
          model: "base",
          computeType: "float32"
        });
        transcript = transcriptJson;
        transcriptText =
          transcript.text ||
          (transcript.segments || [])
            .map((s) => s.text || "")
            .join(" ");
      } catch (err) {
        console.error("‚ùå Story transcription error:", err);
      }
    }
  }

  const userMessage = text || transcriptText;

  // L·∫•y conversation history
  const history = await pool.query(
    `SELECT * FROM story_conversations 
     WHERE session_id = $1 
     ORDER BY created_at DESC 
     LIMIT 10`,
    [sessionId]
  );

  // T·∫°o AI response v·ªõi tone ƒë·ªìng c·∫£m, an ·ªßi
  const aiResponse = await generateStoryResponse(userMessage, history.rows.reverse());

  // L∆∞u messages
  await pool.query(
    `INSERT INTO story_conversations 
     (session_id, message_type, text_content, audio_url, transcript, ai_response)
     VALUES ($1, 'user', $2, $3, $4, $5)`,
    [
      sessionId,
      text || null,
      audioUrl || null,
      transcript ? JSON.stringify(transcript) : null,
      aiResponse
    ]
  );

  return aiResponse;
}

/**
 * T·∫°o AI response cho story mode s·ª≠ d·ª•ng Python trainer (tr√≤ chuy·ªán live nh∆∞ Gemini)
 */
async function generateStoryResponse(userMessage, history) {
  try {
    // G·ªçi Python trainer ƒë·ªÉ t·∫°o conversation AI training
    const trainingData = await getTrainingDataFromPython('conversation_ai', {
      topic: null, // Kh√¥ng c√≥ topic c·ªë ƒë·ªãnh, ƒë·ªÉ conversation t·ª± nhi√™n
      history: history.map(h => ({
        speaker: 'user',
        text_content: h.text_content || "[Audio]",
        ai_response: h.ai_response || ""
      }))
    });
    
    // N·∫øu Python trainer fail, d√πng fallback
    if (!trainingData || !trainingData.system_prompt) {
      return await generateStoryResponseFallback(userMessage, history);
    }
    
    // G·ªçi OpenRouter v·ªõi training data t·ª´ Python qua trainedAIService
    const messages = [
      { role: 'user', content: userMessage }
    ];
    
    const response = await trainedAIService.callTrainedAI(
      'conversation_ai',
      {
        topic: null,
        history: history.map(h => ({
          speaker: 'user',
          text_content: h.text_content || "[Audio]",
          ai_response: h.ai_response || ""
        }))
      },
      messages,
      { model: "openai/gpt-4o-mini", temperature: 0.9, max_tokens: 300 }
    );

    return response.choices?.[0]?.message?.content || "I'm here to listen. Please continue.";
  } catch (err) {
    console.error("‚ùå Story response error:", err);
    return generateStoryResponseFallback(userMessage, history);
  }
}

/**
 * Fallback cho story response
 */
async function generateStoryResponseFallback(userMessage, history) {
  const systemPrompt = `You are a compassionate AI companion. Be warm, empathetic, and natural like Google Gemini's live conversation.

Previous context:
${history.slice(-3).map((h) => 
  `User: ${h.text_content || "[Audio]"} | AI: ${h.ai_response || ""}`
).join("\n")}

User: "${userMessage}"

Respond naturally and empathetically.`;

  try {
    const response = await aiService.callOpenRouter(
      [
        { role: "system", content: systemPrompt },
        { role: "user", content: userMessage }
      ],
      { model: "openai/gpt-4o-mini", temperature: 0.9 }
    );

    return response.choices?.[0]?.message?.content || "I'm here to listen. Please continue.";
  } catch (err) {
    return "I understand. Thank you for sharing with me. How are you feeling about this?";
  }
}
=======
v? s?a merge conflict
>>>>>>> Incoming (Background Agent changes)

