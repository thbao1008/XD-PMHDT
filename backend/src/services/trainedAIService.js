/**
 * Trained AI Service - Wrapper Ä‘á»ƒ gá»i OpenRouter qua ai_models training
 * Táº¥t cáº£ AI calls sáº½ Ä‘i qua training layer Ä‘á»ƒ cÃ³ cÆ°á»ng Ä‘á»™ tÆ° duy cao
 */

import * as aiService from "./aiService.js";
import { spawn } from "child_process";
import path from "path";
import { promisify } from "util";

/**
 * Gá»i Python trainer Ä‘á»ƒ táº¡o training data trÆ°á»›c khi gá»i OpenRouter
 * Sá»­ dá»¥ng stdin Ä‘á»ƒ trÃ¡nh lá»—i kÃ½ tá»± Ä‘áº·c biá»‡t trÃªn Windows
 */
async function getTrainingDataFromPython(trainingType, options = {}) {
  return new Promise((resolve, reject) => {
    try {
      const trainerPath = path.join(process.cwd(), "backend", "ai_models", "comprehensiveAITrainer.py");
      
      // Táº¡o data object Ä‘á»ƒ gá»­i qua stdin
      let stdinData = { training_type: trainingType };
      
      if (trainingType === 'prompt_generator') {
        stdinData = {
          training_type: 'prompt_generator',
          level: options.level || 2,
          used_topics: options.usedTopics || [],
          used_prompts: options.usedPrompts || [],
          topics_json: options.topicsJson || "[]",
          challenges_json: options.challengesJson || "[]",
          learner_id: options.learnerId || null,
          personalization_context: options.personalizationContext || null
        };
      } else if (trainingType === 'conversation_ai') {
        stdinData = {
          training_type: 'conversation_ai',
          topic: options.topic || null,
          history: options.history || []
        };
      } else if (trainingType === 'quick_analysis') {
        stdinData = {
          training_type: 'quick_analysis',
          transcript: options.transcript || "",
          expected: options.expected || null,
          level: options.level || 2
        };
      }
      
      // Spawn Python process vá»›i stdin vÃ  set UTF-8 encoding
      const pythonProcess = spawn('python', [trainerPath], {
        stdio: ['pipe', 'pipe', 'pipe'],
        shell: true,
        env: {
          ...process.env,
          PYTHONIOENCODING: 'utf-8'
        }
      });
      
      let stdout = '';
      let stderr = '';
      
      pythonProcess.stdout.on('data', (data) => {
        stdout += data.toString();
      });
      
      pythonProcess.stderr.on('data', (data) => {
        stderr += data.toString();
      });
      
      pythonProcess.on('close', (code) => {
        if (code !== 0) {
          console.error("âŒ Python trainer error:", stderr);
          reject(new Error(`Python trainer exited with code ${code}: ${stderr}`));
          return;
        }
        
        try {
          const result = JSON.parse(stdout);
          resolve(result);
        } catch (err) {
          console.error("âŒ Error parsing Python output:", err);
          console.error("Python stdout:", stdout);
          reject(new Error(`Failed to parse Python output: ${err.message}`));
        }
      });
      
      pythonProcess.on('error', (err) => {
        console.error("âŒ Error spawning Python process:", err);
        reject(err);
      });
      
      // Gá»­i data qua stdin
      pythonProcess.stdin.write(JSON.stringify(stdinData));
      pythonProcess.stdin.end();
      
    } catch (err) {
      console.error("âŒ Error calling Python trainer:", err);
      reject(err);
    }
  });
}

/**
 * Táº¡o random seed vÃ  unique identifier cho má»—i request
 */
function generateRandomSeed() {
  return Math.floor(Math.random() * 1000000) + Date.now();
}

/**
 * Táº¡o unique user message vá»›i randomization
 */
function createRandomizedUserMessage(trainingType, seed) {
  const timestamp = Date.now();
  const randomVariations = [
    `Generate a COMPLETELY NEW and UNIQUE topic and prompt. Use seed ${seed} and timestamp ${timestamp}. Return JSON: {"topic": "topic name", "description": "brief", "suggested_prompt": "sentence"}`,
    `Create a FRESH topic that is DIFFERENT from all previous ones. Random seed: ${seed}. Return JSON: {"topic": "topic name", "description": "brief", "suggested_prompt": "sentence"}`,
    `Generate a NEW topic with maximum creativity. Seed: ${seed}, Time: ${timestamp}. Return JSON: {"topic": "topic name", "description": "brief", "suggested_prompt": "sentence"}`,
    `Create a UNIQUE topic that hasn't been used before. Random: ${seed}. Return JSON: {"topic": "topic name", "description": "brief", "suggested_prompt": "sentence"}`
  ];
  
  // Chá»n random variation dá»±a trÃªn seed
  const variationIndex = seed % randomVariations.length;
  return randomVariations[variationIndex];
}

/**
 * Gá»i OpenRouter vá»›i training data tá»« Python trainer
 * ÄÃ¢y lÃ  hÃ m chÃ­nh Ä‘á»ƒ thay tháº¿ callOpenRouter trá»±c tiáº¿p
 * Vá»›i randomization Ä‘á»ƒ Ä‘áº£m báº£o Ä‘a dáº¡ng
 */
export async function callTrainedAI(trainingType, options = {}, messages = null, aiOpts = {}) {
  try {
    // Táº¡o random seed cho má»—i request Ä‘á»ƒ Ä‘áº£m báº£o Ä‘a dáº¡ng
    const randomSeed = generateRandomSeed();
    const timestamp = Date.now();
    
    // Láº¥y training data tá»« Python trainer
    const trainingData = await getTrainingDataFromPython(trainingType, options);
    
    // Náº¿u training fail, fallback vá» callOpenRouter trá»±c tiáº¿p
    if (!trainingData || !trainingData.system_prompt) {
      console.warn("âš ï¸ Training data not available, using direct OpenRouter call");
      if (messages) {
        return await aiService.callOpenRouter(messages, aiOpts);
      }
      throw new Error("No training data and no messages provided");
    }
    
    // ThÃªm randomization vÃ o system prompt
    const randomizedSystemPrompt = `${trainingData.system_prompt}

RANDOMIZATION PARAMETERS (Critical for diversity):
- Random Seed: ${randomSeed}
- Timestamp: ${timestamp}
- Request ID: ${Math.random().toString(36).substring(7)}
- Use stochastic sampling with high creativity
- Ensure this topic is COMPLETELY DIFFERENT from any previous topics
- Vary sentence structure, vocabulary, and topic angle`;

    // Táº¡o messages tá»« training data
    const trainedMessages = [
      { role: 'system', content: randomizedSystemPrompt }
    ];
    
    // ThÃªm user messages náº¿u cÃ³
    if (messages && Array.isArray(messages)) {
      // TÃ¬m user messages trong messages array
      const userMessages = messages.filter(m => m.role === 'user');
      trainedMessages.push(...userMessages);
    } else if (typeof messages === 'string') {
      trainedMessages.push({ role: 'user', content: messages });
    } else if (trainingType === 'prompt_generator') {
      // Táº¡o randomized user message
      const randomizedUserMessage = createRandomizedUserMessage(trainingType, randomSeed);
      trainedMessages.push({ 
        role: 'user', 
        content: randomizedUserMessage
      });
    } else if (trainingType === 'quick_analysis') {
      trainedMessages.push({ 
        role: 'user', 
        content: `Analyze now. Seed: ${randomSeed}. Return JSON only.` 
      });
    }
    
    // TÃ­nh toÃ¡n sampling parameters Ä‘á»ƒ tÄƒng Ä‘a dáº¡ng
    const baseTemperature = aiOpts.temperature || (trainingData.config?.temperature || 0.95);
    // TÄƒng temperature thÃªm má»™t chÃºt Ä‘á»ƒ Ä‘áº£m báº£o Ä‘a dáº¡ng
    const enhancedTemperature = Math.min(1.2, baseTemperature + 0.1);
    
    // Gá»i OpenRouter vá»›i trained messages vÃ  enhanced sampling
    const response = await aiService.callOpenRouter(
      trainedMessages,
      {
        model: aiOpts.model || 'openai/gpt-4o-mini',
        temperature: enhancedTemperature,
        max_tokens: aiOpts.max_tokens || (trainingData.config?.max_tokens || 250),
        top_p: 0.95, // Nucleus sampling Ä‘á»ƒ tÄƒng Ä‘a dáº¡ng
        frequency_penalty: 0.5, // Penalty cho repetition
        presence_penalty: 0.5 // Penalty cho presence cá»§a tá»« Ä‘Ã£ dÃ¹ng
      }
    );
    
    // Log Ä‘á»ƒ debug
    console.log(`ğŸ² Generated topic with seed: ${randomSeed}, temperature: ${enhancedTemperature}`);
    
    return response;
  } catch (err) {
    console.error("âŒ Error in callTrainedAI:", err);
    // Fallback vá» direct call náº¿u cÃ³ messages
    if (messages) {
      return await aiService.callOpenRouter(messages, aiOpts);
    }
    throw err;
  }
}

/**
 * Wrapper cho prompt generation vá»›i training
 */
export async function generatePromptWithTraining(level, usedTopics = [], usedPrompts = [], 
                                                 learnerId = null, sessionId = null,
                                                 topicsJson = "[]", challengesJson = "[]",
                                                 personalizationContext = null) {
  return await callTrainedAI('prompt_generator', {
    level,
    usedTopics,
    usedPrompts,
    learnerId,
    sessionId,
    topicsJson,
    challengesJson,
    personalizationContext
  }, null, {
    model: 'openai/gpt-4o-mini',
    temperature: 0.95,
    max_tokens: 250
  });
}

/**
 * Wrapper cho conversation AI vá»›i training
 */
export async function conversationAIWithTraining(topic = null, history = [], userMessage = null) {
  const messages = userMessage ? [{ role: 'user', content: userMessage }] : null;
  
  return await callTrainedAI('conversation_ai', {
    topic,
    history
  }, messages, {
    model: 'openai/gpt-4o-mini',
    temperature: 0.9,
    max_tokens: 300
  });
}

/**
 * Wrapper cho quick analysis vá»›i training
 */
export async function quickAnalysisWithTraining(transcript, expectedText = null, level = 2) {
  return await callTrainedAI('quick_analysis', {
    transcript,
    expected: expectedText,
    level
  }, null, {
    model: 'openai/gpt-4o-mini',
    temperature: 0.5,
    max_tokens: 200
  });
}

/**
 * Export callOpenRouter Ä‘á»ƒ backward compatibility
 * NhÆ°ng khuyáº¿n khÃ­ch sá»­ dá»¥ng callTrainedAI
 */
export { callOpenRouter } from "./aiService.js";

