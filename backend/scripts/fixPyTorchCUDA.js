/**
 * Script kh·∫Øc ph·ª•c PyTorch b·ªã downgrade v·ªÅ CPU
 * Ch·∫°y script n√†y n·∫øu PyTorch b·ªã thay ƒë·ªïi th√†nh CPU version
 */
import { execSync } from 'child_process';

const pythonCmd = 'py -3'; // Ho·∫∑c 'python' t√πy h·ªá th·ªëng

console.log('='.repeat(60));
console.log('üîß Kh·∫Øc ph·ª•c PyTorch b·ªã downgrade v·ªÅ CPU');
console.log('='.repeat(60));

try {
  // 1. Ki·ªÉm tra PyTorch hi·ªán t·∫°i
  console.log('\n1. Ki·ªÉm tra PyTorch hi·ªán t·∫°i...');
  const currentTorch = execSync(`${pythonCmd} -c "import torch; print(torch.__version__); print('CUDA:', torch.version.cuda if torch.cuda.is_available() else 'CPU'); print('GPU:', torch.cuda.is_available())"`, {
    encoding: 'utf-8',
    shell: true
  });
  console.log(currentTorch);
  
  const lines = currentTorch.trim().split('\n');
  const version = lines[0];
  const cuda = lines[1];
  const gpu = lines[2];
  
  if (version.includes('+cu') && gpu.includes('True')) {
    console.log('‚úÖ PyTorch CUDA ƒë√£ ƒë√∫ng, kh√¥ng c·∫ßn s·ª≠a!');
    process.exit(0);
  }
  
  console.log('\n‚ö†Ô∏è  PyTorch ƒëang l√† CPU version ho·∫∑c kh√¥ng c√≥ GPU!');
  console.log('üîß ƒêang kh·∫Øc ph·ª•c...\n');
  
  // 2. G·ª° PyTorch CPU
  console.log('2. G·ª° PyTorch CPU...');
  try {
    execSync(`${pythonCmd} -m pip uninstall torch torchvision torchaudio -y`, {
      stdio: 'inherit',
      shell: true
    });
    console.log('‚úÖ ƒê√£ g·ª° PyTorch CPU');
  } catch (e) {
    console.log('‚ö†Ô∏è  Kh√¥ng th·ªÉ g·ª° (c√≥ th·ªÉ ƒë√£ g·ª° r·ªìi)');
  }
  
  // 3. C√†i l·∫°i PyTorch CUDA 2.5.1+cu121 (version CUDA cao nh·∫•t hi·ªán c√≥)
  console.log('\n3. C√†i l·∫°i PyTorch CUDA 2.5.1+cu121...');
  console.log('   (Version CUDA cao nh·∫•t hi·ªán c√≥, c√≥ th·ªÉ m·∫•t v√†i ph√∫t...)');
  execSync(`${pythonCmd} -m pip install torch==2.5.1+cu121 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121`, {
    stdio: 'inherit',
    shell: true
  });
  console.log('‚úÖ ƒê√£ c√†i PyTorch CUDA 2.5.1+cu121');
  
  // 4. Verify
  console.log('\n4. Ki·ªÉm tra l·∫°i...');
  const newTorch = execSync(`${pythonCmd} -c "import torch; print(torch.__version__); print('CUDA:', torch.version.cuda if torch.cuda.is_available() else 'CPU'); print('GPU:', torch.cuda.is_available())"`, {
    encoding: 'utf-8',
    shell: true
  });
  console.log(newTorch);
  
  const newLines = newTorch.trim().split('\n');
  const newVersion = newLines[0];
  const newCuda = newLines[1];
  const newGpu = newLines[2];
  
  if (newVersion.includes('+cu') && newGpu.includes('True')) {
    console.log('\n‚úÖ Kh·∫Øc ph·ª•c th√†nh c√¥ng! PyTorch CUDA ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t.');
    console.log('üí° B√¢y gi·ªù c√†i WhisperX v·ªõi:');
    console.log('   py -3 -m pip install whisperx --no-deps');
    console.log('   py -3 -m pip install faster-whisper --no-deps');
    console.log('   py -3 -m pip install transformers');
    console.log('   py -3 -m pip install pyannote.audio --no-deps');
    console.log('   py -3 -m pip install lightning pytorch-lightning pyannote-core pyannote-database pyannote-metrics pyannote-pipeline pyannoteai-sdk torch-audiomentations opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp');
  } else {
    console.log('\n‚ùå V·∫´n ch∆∞a ƒë√∫ng. Ki·ªÉm tra l·∫°i c√†i ƒë·∫∑t CUDA Toolkit.');
  }
  
} catch (error) {
  console.error('\n‚ùå L·ªói:', error.message);
  process.exit(1);
}

