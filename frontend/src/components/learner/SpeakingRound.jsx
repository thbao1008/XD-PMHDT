import React, { useState, useEffect, useRef } from "react";
import AudioRecorder from "../common/AudioRecorder";
import api from "../../api";
import { FaMicrophone } from "react-icons/fa";
import "../../styles/speaking-practice.css";

export default function SpeakingRound({
  sessionId,
  roundNumber,
  level,
  onSave,
  onCancel
}) {
  const [prompt, setPrompt] = useState("");
  const [timeLimit, setTimeLimit] = useState(30);
  const [timeRemaining, setTimeRemaining] = useState(timeLimit);
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState(null);
  const [submitting, setSubmitting] = useState(false);
  const [analysis, setAnalysis] = useState(null);
  const [showAnalysis, setShowAnalysis] = useState(false);
  const [loadingAnalysis, setLoadingAnalysis] = useState(false);
  const [translation, setTranslation] = useState("");
  const [showTranslation, setShowTranslation] = useState(false);
  const [wordTooltip, setWordTooltip] = useState(null);
  const [countdown, setCountdown] = useState(null);
  const [showPrompt, setShowPrompt] = useState(false); // Ch·ªâ hi·ªÉn th·ªã prompt sau countdown
  const [highlightedWords, setHighlightedWords] = useState(new Set()); // T·ª´ ƒë√£ ƒë∆∞·ª£c n√≥i ƒë√∫ng
  const timerRef = useRef(null);
  const countdownRef = useRef(null);
  const startTimeRef = useRef(null);
  const audioRecorderRef = useRef(null);
  const promptDataRef = useRef(null); // L∆∞u prompt data ƒë·ªÉ hi·ªÉn th·ªã sau
  const recognitionRef = useRef(null); // Web Speech API recognition
  const isRecordingRef = useRef(false); // Ref ƒë·ªÉ track recording state
  const mediaRecorderRef = useRef(null); // MediaRecorder instance
  const mediaStreamRef = useRef(null); // MediaStream from getUserMedia
  const audioChunksRef = useRef([]); // Audio chunks for MediaRecorder

  // L·∫•y prompt t·ª´ backend v√† t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu
  useEffect(() => {
    fetchPrompt();
    // T·ª± ƒë·ªông b·∫Øt ƒë·∫ßu sau khi fetch prompt (kh√¥ng c·∫ßn countdown v√† n√∫t "B·∫Øt ƒë·∫ßu")
    const autoStartTimer = setTimeout(() => {
      if (promptDataRef.current && !isRecording && !showPrompt) {
        console.log("üöÄ Auto-starting round...");
        startRecording();
      }
    }, 800); // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ prompt data ƒë∆∞·ª£c set
    
    return () => clearTimeout(autoStartTimer);
  }, [sessionId, roundNumber, level]);

  // B·ªè countdown - kh√¥ng c·∫ßn n·ªØa v√¨ t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu

  // Timer countdown khi ƒëang ghi √¢m
  useEffect(() => {
    if (isRecording && timeRemaining > 0) {
      timerRef.current = setInterval(() => {
        setTimeRemaining((prev) => {
          if (prev <= 1) {
            // Khi h·∫øt th·ªùi gian, ƒë√°nh d·∫•u ƒë·ªÉ submit sau khi audio ƒë∆∞·ª£c t·∫°o
            finishEarlyRef.current = true;
            stopRecording();
            return 0;
          }
          return prev - 1;
        });
      }, 1000);
    } else {
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    }

    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
    };
  }, [isRecording, timeRemaining]);

  // T·ª± ƒë·ªông submit khi ƒë√£ highlight h·∫øt t·∫•t c·∫£ t·ª´
  useEffect(() => {
    if (!isRecording || submitting) {
      console.log("‚è∏Ô∏è Auto-submit check skipped:", { isRecording, submitting });
      return;
    }
    
    const currentPrompt = prompt || promptDataRef.current?.prompt || "";
    if (!currentPrompt) {
      console.log("‚è∏Ô∏è No prompt available for auto-submit check");
      return;
    }
    
    const expectedWords = currentPrompt.toLowerCase().split(/\s+/).filter(w => w.length > 0);
    console.log("üîç Auto-submit check:", {
      highlighted: highlightedWords.size,
      expected: expectedWords.length,
      isComplete: highlightedWords.size >= expectedWords.length
    });
    
    // Ki·ªÉm tra n·∫øu ƒë√£ highlight h·∫øt
    if (highlightedWords.size >= expectedWords.length) {
      console.log("üéâ All words completed! Stopping recording and will auto-submit...");
      // ƒê√°nh d·∫•u ƒë·ªÉ submit
      finishEarlyRef.current = true;
      
      // ƒê·ª£i m·ªôt ch√∫t r·ªìi d·ª´ng recording ƒë·ªÉ ƒë·∫£m b·∫£o audio ƒë√£ ƒë∆∞·ª£c ghi ƒë·ªß
      setTimeout(() => {
        console.log("üõë Stopping recording (all words completed)...");
        // Stop MediaRecorder directly (kh√¥ng c·∫ßn ref)
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
          console.log("‚úÖ Stopping MediaRecorder...");
          mediaRecorderRef.current.stop();
        } else {
          console.log("‚ö†Ô∏è MediaRecorder not active, calling stopRecording()");
          stopRecording(); // D·ª´ng speech recognition v√† cleanup
        }
      }, 500);
    }
  }, [highlightedWords.size, isRecording, submitting, prompt, audioBlob]);

  const fetchPrompt = async () => {
    try {
      const res = await api.get(
        `/learners/speaking-practice/sessions/${sessionId}/prompt`,
        { params: { round: roundNumber, level } }
      );
      // L∆∞u prompt data nh∆∞ng ch∆∞a hi·ªÉn th·ªã
      promptDataRef.current = {
        prompt: res.data.prompt,
        timeLimit: res.data.time_limit || 30
      };
      setTimeLimit(res.data.time_limit || 30);
      // Reset c√°c state khi fetch prompt m·ªõi
      setPrompt("");
      setShowPrompt(false);
      setAudioBlob(null);
      setAnalysis(null);
      setShowAnalysis(false);
      setTranslation("");
      setSubmitting(false);
      setIsRecording(false);
      isRecordingRef.current = false;
      setHighlightedWords(new Set());
      setTimeRemaining(res.data.time_limit || 30);
      setCountdown(null); // Reset countdown
    } catch (err) {
      console.error("‚ùå Error fetching prompt:", err);
    }
  };

  // B·ªè startCountdown - kh√¥ng c·∫ßn n·ªØa v√¨ t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu

  const startRecording = () => {
    console.log("üé¨ startRecording called");
    
    // Hi·ªÉn th·ªã prompt v√† b·∫Øt ƒë·∫ßu ghi √¢m
    if (promptDataRef.current) {
      console.log("üìù Prompt data:", promptDataRef.current);
      const promptText = promptDataRef.current.prompt;
      setPrompt(promptText);
      setTimeLimit(promptDataRef.current.timeLimit);
      setTimeRemaining(promptDataRef.current.timeLimit);
      setShowPrompt(true);
      
      // ƒê·∫£m b·∫£o prompt ƒë∆∞·ª£c set tr∆∞·ªõc khi start speech recognition
      console.log("‚úÖ Prompt set to:", promptText);
    } else {
      console.warn("‚ö†Ô∏è No prompt data available");
      return; // Kh√¥ng start n·∫øu kh√¥ng c√≥ prompt
    }
    
    setIsRecording(true);
    isRecordingRef.current = true;
    startTimeRef.current = Date.now();
    setHighlightedWords(new Set()); // Reset highlighted words
    
    // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o prompt state ƒë√£ ƒë∆∞·ª£c update v√† refs ƒë∆∞·ª£c mount
    setTimeout(async () => {
      // Start Web Speech API for real-time recognition
      startSpeechRecognition();
      
      // Start audio recording directly using MediaRecorder
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamRef.current = stream;
        audioChunksRef.current = [];
        
        const options = 
          typeof MediaRecorder !== "undefined" &&
          MediaRecorder.isTypeSupported &&
          MediaRecorder.isTypeSupported("audio/webm")
            ? { mimeType: "audio/webm" }
            : undefined;
        
        const mr = new MediaRecorder(stream, options);
        mediaRecorderRef.current = mr;
        
        mr.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) {
            audioChunksRef.current.push(e.data);
          }
        };
        
        mr.onstop = () => {
          const blob = new Blob(audioChunksRef.current, { 
            type: audioChunksRef.current[0]?.type || "audio/webm" 
          });
          console.log("üé§ MediaRecorder stopped, blob created:", blob.size, "bytes");
          handleAudioRecorded(blob);
          
          // Stop all tracks
          if (mediaStreamRef.current) {
            mediaStreamRef.current.getTracks().forEach(track => track.stop());
            mediaStreamRef.current = null;
          }
        };
        
        mr.start();
        console.log("‚úÖ MediaRecorder started directly");
      } catch (err) {
        console.error("‚ùå Error starting MediaRecorder:", err);
        // Fallback to AudioRecorder if available
        if (audioRecorderRef.current && audioRecorderRef.current.startRecording) {
          audioRecorderRef.current.startRecording();
        } else {
          console.error("‚ùå AudioRecorder also not available");
        }
      }
    }, 100);
  };

  const startSpeechRecognition = () => {
    console.log("üé§ Starting speech recognition...");
    
    // Check if browser supports Web Speech API
    if (!("webkitSpeechRecognition" in window) && !("SpeechRecognition" in window)) {
      console.warn("‚ö†Ô∏è Web Speech API not supported");
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = "en-US";

    recognition.onresult = (event) => {
      console.log("üó£Ô∏è Speech recognition result:", event);
      
      // S·ª≠ d·ª•ng prompt t·ª´ ref ho·∫∑c state
      const currentPrompt = prompt || promptDataRef.current?.prompt || "";
      
      if (!currentPrompt) {
        console.warn("‚ö†Ô∏è No prompt available, prompt:", prompt, "promptDataRef:", promptDataRef.current);
        return;
      }
      
      console.log("üìù Using prompt:", currentPrompt);
      const expectedWords = currentPrompt.toLowerCase().split(/\s+/).filter(w => w.length > 0);
      
      // L·∫•y T·∫§T C·∫¢ k·∫øt qu·∫£ (c·∫£ interim v√† final) ƒë·ªÉ highlight real-time nh∆∞ Duolingo
      let fullTranscript = "";
      for (let i = 0; i < event.results.length; i++) {
        fullTranscript += event.results[i][0].transcript + " ";
      }
      
      if (!fullTranscript.trim()) {
        console.log("‚ö†Ô∏è Empty transcript");
        return;
      }
      
      console.log("üìù Full transcript:", fullTranscript);
      
      const spokenWords = fullTranscript.toLowerCase().trim().split(/\s+/).filter(w => w.length > 0);
      
      console.log("üìä Expected words:", expectedWords);
      console.log("üó£Ô∏è Spoken words:", spokenWords);
      
      // So s√°nh t·ª´ng t·ª´ ƒë√£ n√≥i v·ªõi prompt theo th·ª© t·ª± CH·∫∂T CH·∫º (gi·ªëng Duolingo)
      // Ch·ªâ highlight t·ª´ khi n√≥i ƒê√öNG TH·ª® T·ª∞ t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi
      setHighlightedWords(prev => {
        const newHighlighted = new Set();
        let spokenIdx = 0;
        let lastHighlightedIdx = -1;
        
        // T√¨m t·ª´ cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c highlight ƒë·ªÉ ch·ªâ ti·∫øp t·ª•c t·ª´ ƒë√≥
        for (let i = expectedWords.length - 1; i >= 0; i--) {
          if (prev.has(i)) {
            lastHighlightedIdx = i;
            break;
          }
        }
        
        // Ch·ªâ t√¨m t·ª´ ti·∫øp theo (kh√¥ng ƒë∆∞·ª£c skip)
        const nextExpectedIdx = lastHighlightedIdx + 1;
        if (nextExpectedIdx >= expectedWords.length) {
          // ƒê√£ highlight h·∫øt r·ªìi
          return prev;
        }
        
        const expectedWord = expectedWords[nextExpectedIdx];
        const cleanExpected = expectedWord.replace(/[.,!?;:]/g, "").toLowerCase();
        
        // T√¨m t·ª´ t∆∞∆°ng ·ª©ng trong spoken words (t·ª´ v·ªã tr√≠ hi·ªán t·∫°i)
        for (let j = spokenIdx; j < spokenWords.length; j++) {
          const cleanSpoken = spokenWords[j].replace(/[.,!?;:]/g, "").toLowerCase();
          
          // So s√°nh ch√≠nh x√°c ho·∫∑c g·∫ßn ƒë√∫ng
          if (cleanSpoken === cleanExpected) {
            // Kh·ªõp ch√≠nh x√°c
            console.log(`‚úÖ Matched word ${nextExpectedIdx} (in order): "${cleanExpected}"`);
            newHighlighted.add(nextExpectedIdx);
            break;
          } else if (cleanSpoken.length > 0 && cleanExpected.length > 0) {
            // Ki·ªÉm tra similarity
            const similarity = calculateSimilarity(cleanSpoken, cleanExpected);
            if (similarity > 0.7) {
              // Kh·ªõp g·∫ßn ƒë√∫ng (>70%)
              console.log(`‚úÖ Matched word ${nextExpectedIdx} (similarity ${similarity.toFixed(2)}, in order): "${cleanExpected}"`);
              newHighlighted.add(nextExpectedIdx);
              break;
            }
          }
        }
        
        if (newHighlighted.size > 0) {
          const combined = new Set([...prev, ...newHighlighted]);
          console.log("‚ú® New highlighted words:", Array.from(newHighlighted));
          console.log("üìä Total highlighted:", combined.size, "/", expectedWords.length);
          
          // Ki·ªÉm tra n·∫øu ƒë√£ highlight h·∫øt t·∫•t c·∫£ t·ª´
          if (combined.size >= expectedWords.length) {
            console.log("üéâ All words highlighted! Will auto-submit when audio is ready...");
            // ƒê√°nh d·∫•u ƒë·ªÉ submit khi audio ƒë∆∞·ª£c record
            finishEarlyRef.current = true;
          }
          
          return combined;
        }
        
        return prev; // Kh√¥ng c√≥ thay ƒë·ªïi
      });
    };
    
    // Helper function ƒë·ªÉ t√≠nh similarity gi·ªØa 2 t·ª´
    const calculateSimilarity = (str1, str2) => {
      const longer = str1.length > str2.length ? str1 : str2;
      const shorter = str1.length > str2.length ? str2 : str1;
      
      if (longer.length === 0) return 1.0;
      
      // Ki·ªÉm tra n·∫øu m·ªôt t·ª´ ch·ª©a t·ª´ kia
      if (longer.includes(shorter)) return 0.8;
      
      // T√≠nh s·ªë k√Ω t·ª± gi·ªëng nhau ·ªü ƒë·∫ßu
      let matchCount = 0;
      const minLen = Math.min(longer.length, shorter.length);
      for (let i = 0; i < minLen; i++) {
        if (longer[i] === shorter[i]) matchCount++;
      }
      
      return matchCount / longer.length;
    };

    recognition.onerror = (event) => {
      console.error("Speech recognition error:", event.error);
    };

    recognition.onend = () => {
      // T·ª± ƒë·ªông restart n·∫øu v·∫´n ƒëang recording
      // S·ª≠ d·ª•ng ref ƒë·ªÉ l·∫•y gi√° tr·ªã m·ªõi nh·∫•t
      setTimeout(() => {
        if (isRecordingRef.current && recognitionRef.current === recognition) {
          try {
            recognition.start();
          } catch (e) {
            // Ignore errors when restarting
          }
        }
      }, 100);
    };

    recognitionRef.current = recognition;
    
    try {
      recognition.start();
    } catch (err) {
      console.error("Failed to start speech recognition:", err);
    }
  };

  const stopRecording = () => {
    setIsRecording(false);
    isRecordingRef.current = false;
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
    
    // Stop speech recognition
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {
        // Ignore errors
      }
      recognitionRef.current = null;
    }
    
    // Stop MediaRecorder directly
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      console.log("üõë Stopping MediaRecorder directly...");
      mediaRecorderRef.current.stop();
    }
    
    // Fallback to AudioRecorder if available
    if (audioRecorderRef.current && audioRecorderRef.current.stopRecording) {
      audioRecorderRef.current.stopRecording();
    }
    
    // Stop media stream tracks
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
  };

  const finishEarlyRef = useRef(false);

  const handleAudioRecorded = (blob) => {
    console.log("üé§ Audio recorded, finishEarly:", finishEarlyRef.current);
    setAudioBlob(blob);
    
    // N·∫øu ƒëang trong qu√° tr√¨nh finish early (b·∫•m n√∫t ho·∫∑c auto-submit), submit ngay
    if (finishEarlyRef.current) {
      finishEarlyRef.current = false;
      stopRecording();
      // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o audio ƒë√£ ƒë∆∞·ª£c t·∫°o ho√†n to√†n
      setTimeout(() => {
        console.log("‚è© Auto-submitting (all words completed)...");
        handleSubmit(blob);
      }, 500);
    } else {
      // Ki·ªÉm tra xem ƒë√£ highlight h·∫øt ch∆∞a
      const currentPrompt = prompt || promptDataRef.current?.prompt || "";
      if (currentPrompt) {
        const expectedWords = currentPrompt.toLowerCase().split(/\s+/).filter(w => w.length > 0);
        const currentHighlighted = highlightedWords.size;
        console.log("üìä Checking highlighted words after recording:", currentHighlighted, "/", expectedWords.length);
        if (currentHighlighted >= expectedWords.length) {
          console.log("üéâ All words completed after recording, auto-submitting...");
          // ƒê·ª£i m·ªôt ch√∫t r·ªìi submit
          setTimeout(() => {
            handleSubmit(blob);
          }, 500);
        }
      }
      stopRecording();
    }
  };

  const handleFinishEarly = () => {
    console.log("‚è© handleFinishEarly called, isRecording:", isRecording, "audioBlob:", !!audioBlob);
    
    if (isRecording) {
      // ƒê√°nh d·∫•u l√† mu·ªën finish early
      finishEarlyRef.current = true;
      console.log("‚úÖ Set finishEarlyRef to true");
      
      // D·ª´ng AudioRecorder tr∆∞·ªõc
      if (audioRecorderRef.current && audioRecorderRef.current.stopRecording) {
        console.log("üõë Stopping AudioRecorder...");
        audioRecorderRef.current.stopRecording();
      } else {
        console.warn("‚ö†Ô∏è AudioRecorder ref not available for stop");
      }
      
      // D·ª´ng ghi √¢m s·ªõm
      stopRecording();
      
      // N·∫øu kh√¥ng c√≥ audioRecorderRef, th·ª≠ submit v·ªõi audioBlob hi·ªán t·∫°i ho·∫∑c ƒë·ª£i
      if (!audioRecorderRef.current && audioBlob) {
        console.log("üì§ AudioRecorder ref missing, but have audioBlob, submitting...");
        setTimeout(() => {
          handleSubmit(audioBlob);
        }, 500);
      }
    } else if (audioBlob) {
      // N·∫øu ƒë√£ c√≥ audio, submit ngay
      console.log("üì§ Submitting existing audio...");
      handleSubmit(audioBlob);
    } else {
      console.warn("‚ö†Ô∏è No recording or audio available");
    }
  };

  const handleSubmit = async (blob = null) => {
    const audio = blob || audioBlob;
    if (!audio) {
      alert("Vui l√≤ng ghi √¢m tr∆∞·ªõc khi n·ªôp b√†i");
      return;
    }

    if (submitting) {
      console.log("‚ö†Ô∏è Already submitting, skipping...");
      return; // Tr√°nh submit nhi·ªÅu l·∫ßn
    }

    console.log("üì§ Starting submit process...");
    setSubmitting(true);
    const timeTaken = startTimeRef.current
      ? Math.floor((Date.now() - startTimeRef.current) / 1000)
      : timeLimit - timeRemaining;

    try {
      // G·ª≠i audio
      const formData = new FormData();
      formData.append("audio", audio);
      formData.append("time_taken", timeTaken);
      formData.append("round_number", roundNumber);

      const res = await api.post(
        `/learners/speaking-practice/sessions/${sessionId}/rounds`,
        formData,
        { headers: { "Content-Type": "multipart/form-data" } }
      );

      console.log("‚úÖ Round submitted, round_id:", res.data.round_id);

      // ƒê·ª£i analysis t·ª´ backend
      setLoadingAnalysis(true);
      const roundId = res.data.round_id;
      
      // Polling ƒë·ªÉ l·∫•y analysis
      const pollAnalysis = async (retries = 30) => {
        try {
          const analysisRes = await api.get(
            `/learners/speaking-practice/sessions/${sessionId}/rounds/${roundId}/analysis`
          );
          
          if (analysisRes.data && analysisRes.data.analysis) {
            console.log("‚úÖ Analysis received:", analysisRes.data);
            setAnalysis({
              ...analysisRes.data.analysis,
              round_id: roundId,
              time_taken: timeTaken
            });
            setShowAnalysis(true);
            setLoadingAnalysis(false);
            setSubmitting(false);
          } else if (retries > 0) {
            // Ch∆∞a c√≥ analysis, ƒë·ª£i th√™m
            setTimeout(() => pollAnalysis(retries - 1), 2000);
          } else {
            // Timeout, chuy·ªÉn v√≤ng m√† kh√¥ng c√≥ analysis
            console.warn("‚ö†Ô∏è Analysis timeout, proceeding without analysis");
            setLoadingAnalysis(false);
            setSubmitting(false);
            const roundData = {
              audioBlob: audio,
              timeTaken,
              prompt: prompt || promptDataRef.current?.prompt || "",
              round_id: roundId
            };
            if (onSave && typeof onSave === 'function') {
              onSave(roundData);
            }
          }
        } catch (err) {
          if (retries > 0) {
            setTimeout(() => pollAnalysis(retries - 1), 2000);
          } else {
            console.error("‚ùå Error fetching analysis:", err);
            setLoadingAnalysis(false);
            setSubmitting(false);
            // Chuy·ªÉn v√≤ng m√† kh√¥ng c√≥ analysis
            const roundData = {
              audioBlob: audio,
              timeTaken,
              prompt: prompt || promptDataRef.current?.prompt || "",
              round_id: roundId
            };
            if (onSave && typeof onSave === 'function') {
              onSave(roundData);
            }
          }
        }
      };
      
      // B·∫Øt ƒë·∫ßu polling sau 2 gi√¢y
      setTimeout(() => pollAnalysis(), 2000);
    } catch (err) {
      console.error("‚ùå Error submitting round:", err);
      alert("C√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i.");
      setSubmitting(false);
    }
  };

  const handleTranslationSubmit = async () => {
    if (!translation.trim()) {
      alert("Vui l√≤ng vi·∫øt nghƒ©a c·ªßa ƒëo·∫°n vƒÉn");
      return;
    }

    try {
      // G·ª≠i translation ƒë·ªÉ AI ki·ªÉm tra
      const res = await api.post(
        `/learners/speaking-practice/sessions/${sessionId}/rounds/${analysis?.round_id}/translation`,
        { translation }
      );

      if (res.data.correct) {
        alert("Ch√≠nh x√°c! B·∫°n ƒë√£ hi·ªÉu ƒë√∫ng nghƒ©a c·ªßa ƒëo·∫°n vƒÉn.");
        // Chuy·ªÉn sang v√≤ng ti·∫øp theo
        onSave({
          audioBlob,
          timeTaken: analysis?.time_taken,
          prompt,
          round_id: analysis?.round_id,
          translation: translation
        });
      } else {
        alert(`Ch∆∞a ch√≠nh x√°c. ${res.data.feedback || "H√£y th·ª≠ l·∫°i."}`);
      }
    } catch (err) {
      console.error("‚ùå Error submitting translation:", err);
      alert("C√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i.");
    }
  };

  const fetchWordDefinition = async (word) => {
    try {
      const res = await api.get(`/learners/dictionary/${encodeURIComponent(word)}`);
      return res.data;
    } catch (err) {
      console.error("‚ùå Error fetching word definition:", err);
      return null;
    }
  };

  const handleWordHover = async (word) => {
    const definition = await fetchWordDefinition(word);
    if (definition) {
      setWordTooltip({ word, ...definition });
    }
  };

  const formatTime = (seconds) => {
    const m = Math.floor(seconds / 60);
    const s = seconds % 60;
    return `${m}:${s.toString().padStart(2, "0")}`;
  };

  // B·ªè countdown overlay - kh√¥ng c·∫ßn n·ªØa v√¨ t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu

  // Hi·ªÉn th·ªã m√†n h√¨nh ph√¢n t√≠ch sau khi n√≥i xong
  if (showAnalysis && analysis) {
    return (
      <div className="speaking-round">
        <div className="round-header">
          <h3>V√≤ng {roundNumber}/10 - K·∫øt qu·∫£</h3>
          <button className="btn-cancel" onClick={onCancel}>
            H·ªßy
          </button>
        </div>

        <div className="analysis-section" style={{ padding: 20 }}>
          <h4>ƒê√°nh gi√° ph√°t √¢m:</h4>
          
          {/* ƒêi·ªÉm t·ªïng qu√°t */}
          <div className="analysis-scores" style={{ display: "flex", gap: 20, marginBottom: 20 }}>
            {analysis.vocabulary_score !== undefined && (
              <div className="analysis-score-card" style={{ flex: 1, padding: 15, background: "#f0f9ff", borderRadius: 8 }}>
                <div style={{ fontSize: 14, color: "#666", marginBottom: 5 }}>ƒêi·ªÉm t·ª´ v·ª±ng</div>
                <div style={{ fontSize: 32, fontWeight: "bold", color: "#10b981" }}>
                  {analysis.vocabulary_score}/10
                </div>
              </div>
            )}
            {analysis.speaking_score !== undefined && (
              <div className="analysis-score-card" style={{ flex: 1, padding: 15, background: "#f0f9ff", borderRadius: 8 }}>
                <div style={{ fontSize: 14, color: "#666", marginBottom: 5 }}>ƒêi·ªÉm n√≥i</div>
                <div style={{ fontSize: 32, fontWeight: "bold", color: "#10b981" }}>
                  {analysis.speaking_score}/10
                </div>
              </div>
            )}
          </div>

          {/* T·ªëc ƒë·ªô n√≥i */}
          {analysis.speech_rate !== undefined && (
            <div className="analysis-item" style={{ marginBottom: 15 }}>
              <strong>T·ªëc ƒë·ªô n√≥i:</strong> {analysis.speech_rate} t·ª´/ph√∫t
            </div>
          )}

          {/* Ng·ªØ ph√°p */}
          {analysis.grammar_errors && analysis.grammar_errors.length > 0 && (
            <div className="analysis-item" style={{ marginBottom: 15 }}>
              <strong>L·ªói ng·ªØ ph√°p:</strong>
              <ul style={{ marginTop: 5, paddingLeft: 20 }}>
                {analysis.grammar_errors.map((error, idx) => (
                  <li key={idx}>{error}</li>
                ))}
              </ul>
            </div>
          )}

          {/* S·ªë t·ª´ ch∆∞a n√≥i ƒë∆∞·ª£c */}
          {analysis.missing_words && analysis.missing_words.length > 0 && (
            <div className="analysis-item" style={{ marginBottom: 15 }}>
              <strong>S·ªë t·ª´ ch∆∞a n√≥i ƒë∆∞·ª£c:</strong> {analysis.missing_words.length}
              <div style={{ marginTop: 5, color: "#666" }}>
                {analysis.missing_words.join(", ")}
              </div>
            </div>
          )}

          {/* Feedback t·ªïng qu√°t */}
          {analysis.feedback && (
            <div className="analysis-feedback" style={{ marginTop: 15, padding: 15, background: "#f9fafb", borderRadius: 8 }}>
              <strong>Nh·∫≠n x√©t:</strong>
              <p style={{ marginTop: 5 }}>{analysis.feedback}</p>
            </div>
          )}
        </div>

        {/* Ph·∫ßn nh·∫≠p nghƒ©a */}
        {!showTranslation ? (
          <div className="translation-section" style={{ marginTop: 30, padding: 20 }}>
            <h4>Vi·∫øt l·∫°i nghƒ©a c·ªßa ƒëo·∫°n vƒÉn:</h4>
            <div className="prompt-text" style={{ position: "relative", marginBottom: 15, padding: 15, background: "#f9fafb", borderRadius: 8 }}>
              {prompt.split(/\s+/).map((word, idx) => {
                const cleanWord = word.replace(/[.,!?;:]/g, "").toLowerCase();
                return (
                  <span
                    key={idx}
                    className="prompt-word"
                    onMouseEnter={() => handleWordHover(cleanWord)}
                    onMouseLeave={() => setWordTooltip(null)}
                    style={{ cursor: "pointer", textDecoration: "underline" }}
                  >
                    {word}{" "}
                  </span>
                );
              })}
              {wordTooltip && (
                <div className="word-tooltip">
                  <div className="tooltip-word">
                    <strong>{wordTooltip.word}</strong>
                  </div>
                  {wordTooltip.pronunciation && (
                    <div className="tooltip-pronunciation" style={{ marginTop: 8, color: "#10b981", fontWeight: "bold" }}>
                      <strong>Ph√°t √¢m:</strong> /{wordTooltip.pronunciation}/
                    </div>
                  )}
                  {wordTooltip.definition && (
                    <div className="tooltip-definition">
                      <strong>Nghƒ©a:</strong> {wordTooltip.definition}
                    </div>
                  )}
                  {wordTooltip.usage && (
                    <div className="tooltip-usage">
                      <strong>C√°ch d√πng:</strong> {wordTooltip.usage}
                    </div>
                  )}
                  {wordTooltip.example && (
                    <div className="tooltip-example">
                      <strong>V√≠ d·ª•:</strong> {wordTooltip.example}
                    </div>
                  )}
                </div>
              )}
            </div>
            <textarea
              value={translation}
              onChange={(e) => setTranslation(e.target.value)}
              rows="4"
              placeholder="Vi·∫øt nghƒ©a ti·∫øng Vi·ªát c·ªßa ƒëo·∫°n vƒÉn tr√™n (ch·ªâ c·∫ßn ƒë√∫ng t∆∞∆°ng ƒë·ªëi)..."
              className="translation-input"
              style={{ width: "100%", padding: 10, borderRadius: 4, border: "1px solid #ddd" }}
            />
            <div className="translation-actions" style={{ marginTop: 15, display: "flex", gap: 10 }}>
              <button
                className="btn-submit"
                onClick={handleTranslationSubmit}
                disabled={!translation.trim()}
                style={{ padding: "10px 20px", background: "#10b981", color: "white", border: "none", borderRadius: 4, cursor: "pointer" }}
              >
                G·ª≠i
              </button>
              <button
                className="btn-skip"
                onClick={() => {
                  // B·ªè qua translation, chuy·ªÉn v√≤ng
                  const roundData = {
                    audioBlob,
                    timeTaken: analysis.time_taken,
                    prompt,
                    round_id: analysis.round_id
                  };
                  if (onSave && typeof onSave === 'function') {
                    onSave(roundData);
                  }
                }}
                style={{ padding: "10px 20px", background: "#6b7280", color: "white", border: "none", borderRadius: 4, cursor: "pointer" }}
              >
                B·ªè qua
              </button>
            </div>
          </div>
        ) : (
          <div className="translation-result" style={{ marginTop: 30, padding: 20, background: "#f0fdf4", borderRadius: 8 }}>
            <p style={{ marginBottom: 15 }}>‚úÖ B·∫°n ƒë√£ ho√†n th√†nh v√≤ng n√†y!</p>
            <button
              className="btn-primary"
              onClick={() => {
                const roundData = {
                  audioBlob,
                  timeTaken: analysis.time_taken,
                  prompt,
                  round_id: analysis.round_id,
                  translation: translation
                };
                if (onSave && typeof onSave === 'function') {
                  onSave(roundData);
                }
              }}
              style={{ padding: "10px 20px", background: "#10b981", color: "white", border: "none", borderRadius: 4, cursor: "pointer" }}
            >
              Ti·∫øp t·ª•c
            </button>
          </div>
        )}
      </div>
    );
  }

  // Hi·ªÉn th·ªã loading khi ƒëang ch·ªù analysis
  if (loadingAnalysis || (submitting && !showAnalysis)) {
    return (
      <div className="speaking-round">
        <div className="round-header">
          <h3>V√≤ng {roundNumber}/10</h3>
          <button className="btn-cancel" onClick={onCancel}>
            H·ªßy
          </button>
        </div>
        <div className="round-content" style={{ textAlign: "center", padding: 40 }}>
          <p style={{ fontSize: 18, color: "#666" }}>ƒêang x·ª≠ l√Ω...</p>
        </div>
      </div>
    );
  }

  // M√†n h√¨nh ch√≠nh - ghi √¢m
  return (
    <div className="speaking-round">
      <div className="round-header">
        <h3>V√≤ng {roundNumber}/10</h3>
        <button className="btn-cancel" onClick={onCancel}>
          H·ªßy
        </button>
      </div>

      <div className="round-content">
        {showPrompt ? (
          <>
            <div className="prompt-section">
              <h4>ƒê·ªçc ƒëo·∫°n vƒÉn sau:</h4>
              <div className="prompt-text" style={{ position: "relative" }}>
                {prompt.split(/\s+/).map((word, idx) => {
                  const cleanWord = word.replace(/[.,!?;:]/g, "").toLowerCase();
                  const isHighlighted = highlightedWords.has(idx);
                  return (
                    <span
                      key={idx}
                      className={`prompt-word ${isHighlighted ? "word-highlighted" : ""}`}
                      onMouseEnter={() => handleWordHover(cleanWord)}
                      onMouseLeave={() => setWordTooltip(null)}
                    >
                      {word}{" "}
                    </span>
                  );
                })}
                {wordTooltip && (
                  <div className="word-tooltip">
                    <div className="tooltip-word">
                      <strong>{wordTooltip.word}</strong>
                    </div>
                    {wordTooltip.pronunciation && (
                      <div className="tooltip-pronunciation" style={{ marginTop: 8, color: "#10b981", fontWeight: "bold" }}>
                        <strong>Ph√°t √¢m:</strong> /{wordTooltip.pronunciation}/
                      </div>
                    )}
                    {wordTooltip.definition && (
                      <div className="tooltip-definition">
                        <strong>Nghƒ©a:</strong> {wordTooltip.definition}
                      </div>
                    )}
                    {wordTooltip.usage && (
                      <div className="tooltip-usage">
                        <strong>C√°ch d√πng:</strong> {wordTooltip.usage}
                      </div>
                    )}
                    {wordTooltip.example && (
                      <div className="tooltip-example">
                        <strong>V√≠ d·ª•:</strong> {wordTooltip.example}
                      </div>
                    )}
                  </div>
                )}
              </div>
              <div className="time-limit">
                Th·ªùi gian: <strong>{formatTime(timeRemaining)}</strong>
              </div>
            </div>

            <div className="recording-section">
              <div className="mic-container">
                <div className={`mic-icon ${isRecording ? "recording" : ""}`}>
                  <FaMicrophone size={64} />
                </div>
                {isRecording && (
                  <div className="recording-waves">
                    <span></span>
                    <span></span>
                    <span></span>
                  </div>
                )}
              </div>
              
              {isRecording && (
                <div className="recording-active">
                  <div className="recording-indicator">
                    <span className="pulse"></span>
                    ƒêang ghi √¢m...
                  </div>
                  <div className="time-remaining">
                    C√≤n l·∫°i: <strong>{formatTime(timeRemaining)}</strong>
                  </div>
                  <div style={{ marginTop: 12, fontSize: 14, color: "#666" }}>
                    N√≥i ƒë√∫ng h·∫øt t·∫•t c·∫£ t·ª´ s·∫Ω t·ª± ƒë·ªông chuy·ªÉn v√≤ng
                  </div>
                </div>
              )}

              {audioBlob && !isRecording && !submitting && (
                <div className="audio-complete">
                  <p style={{ marginBottom: 12, color: "#10b981" }}>
                    ‚úÖ ƒê√£ ghi √¢m xong. ƒêang x·ª≠ l√Ω...
                  </p>
                  <audio controls src={URL.createObjectURL(audioBlob)} style={{ width: "100%", marginBottom: 12 }} />
                </div>
              )}

              {submitting && (
                <div className="submitting-indicator">
                  <p>ƒêang x·ª≠ l√Ω...</p>
                </div>
              )}
            </div>
          </>
        ) : (
          <div className="recording-section">
            <div className="recording-controls">
              <p style={{ textAlign: "center", color: "#666" }}>
                ƒêang t·∫£i ƒë·ªÅ b√†i...
              </p>
            </div>
          </div>
        )}
      </div>
    </div>
  );
}
